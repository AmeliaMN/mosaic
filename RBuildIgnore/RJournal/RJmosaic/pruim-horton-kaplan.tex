% !TeX root = RJwrapper.tex
\title{The mosaic package: helping students to `think with data' using R}
\author{by Randall Pruim, Daniel T Kaplan, Nicholas J Horton}

\maketitle

\abstract{%
The mosaic package provides a simplified and systematic introduction to
the core functionality related to descriptive statistics, visualization,
modeling, and simulation-based inference required in first and second
courses in statistics. This introduction to the package describes some
of the guiding principles behind the design of the package and provides
illustrative examples of several of the most important functions it
implements. These can be combined to help students ``think with data"
using R in their early course work, starting with simple, yet powerful,
declarative commands.
}

\section{Motivation}\label{motivation}

Many have argued that in order to make sense of the increasingly rich
data that is available to them, students need additional facility to
express statistical computations (e.g.,
\cite{NolanTempleLang:2010, Ridgway:2015, HortonBaumerWickham:2015}). To
be able to ``think with data'' (as coined by Diane Lambert of Google),
students need tools for data management, exploratory analysis,
visualization, and modeling. Yet many students enter statistics courses
with little or no computational experience. Our students have
demonstrated that it is feasible to integrate computing into our
curricula early and often, in a way that provides students with success,
confidence, and room to grow.

\section{A guiding principle: Less volume, more
creativity}\label{a-guiding-principle-less-volume-more-creativity}

The \CRANpkg{mosaic} \citep{mosaic} package originated in early attempts
by each of the authors to ease new users into using R, primarily in the
context of undergraduate statistics courses, and, in one case, also in
calculus. One of the guiding principles behind the development of the
\pkg{mosaic} package has been ``Less volume, more creativity''.
Beginners are easily overwhelmed by the scope of R and its many
packages. Often there are multiple ways to accomplish the same task, and
authors of the many packages are not required to follow any particular
style guidelines.

Early on in the development of \pkg{mosaic}, we decided to reduce the
number of commands (R functions) and, more importantly, the number of
code templates (general schemes that unify the usage of several
functions) that users would need to know to as few as possible, while
still providing them with substantial power to be creative within the
templates provided. Choosing a handful of code templates that unify the
approach to using many different functions greatly reduces the cognitive
load for new users.

To successfully implement a ``less volume, more creativity'' approach,
one must decide which tasks are most important to accomplish.\\
The key tasks we wanted our students to master included

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Graphical summaries of data, including multi-variable summaries;
\item
  Numerical summaries of data, including multi-variable summaries;
\item
  The construction, visualization, and interpretation of models (single
  variable distribution models, the usual 1- and 2-sample inference
  procedures, linear regression, ANOVA, logistic regression, etc.); and
\item
  Simulation-based inference.
\end{enumerate}

A one-page list of commands that are more than sufficient for a first
course, originally presented as part of a roundtable discussion at the
Joint Statistics Meetings \citep{Pruim:MinimalR:2011} now appears as a
vignette in the package, along with some additional material on the less
volume, more creativity approach.

\section{The formula template}\label{the-formula-template}

We knew from the outset that we wanted students to be able to create
graphical and numerical summaries of data, to fit various models and to
perform inference procedures (items 1--3 in our list above).\\
Because of these goals, our most important template makes use of a
``formula interface'' that is already used by important R functions like
\code{t.test()}, \code{lm()}, and the plotting functions in
\CRANpkg{lattice} \citep{lattice}.

We typically introduce the formula template in the context of exploring
two variables as

\begin{Schunk}
\begin{Sinput}
goal( y ~ x, data = mydata, ... )    # pseudo-code for the formula template
\end{Sinput}
\end{Schunk}

\noindent
Those familiar with R will recognize this as the template already used
by functions such as \texttt{lm()} and the \pkg{lattice} plotting
functions. The \pkg{mosaic} package extends this template to numerical
summaries and provides some additional features for plotting and fitting
models.

For a plot, \texttt{goal} names the type of plot, \texttt{y} and
\texttt{x} name the variables to be mapped to the vertical and
horizontal axes, \texttt{mydata} is the data frame in which these
variables are found, and \texttt{...} can contain additional options
that further refine the plot. This template allows us to create, for
example, scatterplots and side-by-side box plots using \pkg{lattice}
functions. Here we illustrate using the \texttt{Births78} data set,
which records the number of live births in the United States for each
day of 1978.

\begin{Schunk}
\begin{Sinput}
require(mosaic) 
xyplot(births ~ date, data = Births78)
\end{Sinput}


\begin{center}\includegraphics[width=.45\textwidth]{pruim-horton-kaplan_files/figure-latex/unnamed-chunk-3-1} \end{center}

\end{Schunk}\begin{Schunk}
\begin{Sinput}
bwplot(births ~ wday, data = Births78) 
bwplot(wday ~ births, data = Births78, pch = "|")  # a more common way to show median
\end{Sinput}


\begin{center}\includegraphics[width=.45\textwidth]{pruim-horton-kaplan_files/figure-latex/unnamed-chunk-4-1} \includegraphics[width=.45\textwidth]{pruim-horton-kaplan_files/figure-latex/unnamed-chunk-4-2} \end{center}

\end{Schunk}

\noindent
Using the \pkg{mosaic} package, this same template can be used to
calculate numerical summaries.

\begin{Schunk}
\begin{Sinput}
mean(births ~ wday, data = Births78)
\end{Sinput}
\begin{Soutput}
##   Sun   Mon  Tues   Wed Thurs   Fri   Sat 
##  7951  9371  9709  9498  9484  9626  8309
\end{Soutput}
\begin{Sinput}
sd(births ~ wday, data = Births78)
\end{Sinput}
\begin{Soutput}
##   Sun   Mon  Tues   Wed Thurs   Fri   Sat 
##   410   608   527   461   551   488   390
\end{Soutput}
\begin{Sinput}
favstats(births ~ wday, data = Births78)
\end{Sinput}
\begin{Soutput}
##    wday  min   Q1 median    Q3   max mean  sd  n missing
## 1   Sun 7135 7691   7936  8196  8711 7951 410 53       0
## 2   Mon 7527 9097   9321  9838 10414 9371 608 52       0
## 3  Tues 8433 9304   9668 10084 10711 9709 527 52       0
## 4   Wed 8606 9196   9362  9880 10703 9498 461 52       0
## 5 Thurs 7915 9171   9397  9958 10499 9484 551 52       0
## 6   Fri 8892 9198   9544 10088 10438 9626 488 52       0
## 7   Sat 7527 8007   8260  8586  9170 8309 390 52       0
\end{Soutput}
\end{Schunk}

\noindent
These sorts of aggregated numerical summaries can be calculated in other
ways, but we find the alternatives more difficult for beginners because
they follow entirely different syntax templates from the corresponding
plots even though essentially the same information is being communicated
to R.

\begin{Schunk}
\begin{Sinput}
with(Births78, aggregate(births, FUN = mean, by = list(wday)))
\end{Sinput}
\begin{Soutput}
##   Group.1    x
## 1     Sun 7951
## 2     Mon 9371
## 3    Tues 9709
## 4     Wed 9498
## 5   Thurs 9484
## 6     Fri 9626
## 7     Sat 8309
\end{Soutput}
\begin{Sinput}
with(Births78, tapply(births, wday, mean))
\end{Sinput}
\begin{Soutput}
##   Sun   Mon  Tues   Wed Thurs   Fri   Sat 
##  7951  9371  9709  9498  9484  9626  8309
\end{Soutput}
\end{Schunk}

We introduced the \texttt{tally()} function for counting categorical
variables. We illustrate its use with another data set from
\CRANpkg{mosaicData} \citep{mosaicData}. \texttt{Whickham} contains data
from a UK study that enrolled subjects in 1972-74 and conducted a
follow-up 20 years later.

\begin{Schunk}
\begin{Sinput}
tally(outcome ~ smoker, data = Whickham)
\end{Sinput}
\begin{Soutput}
##        smoker
## outcome  No Yes
##   Alive 502 443
##   Dead  230 139
\end{Soutput}
\begin{Sinput}
tally(outcome ~ smoker, data = Whickham, margins = TRUE)
\end{Sinput}
\begin{Soutput}
##        smoker
## outcome  No Yes
##   Alive 502 443
##   Dead  230 139
##   Total 732 582
\end{Soutput}
\begin{Sinput}
tally(outcome ~ smoker, data = Whickham, margins = TRUE, format = "proportion")
\end{Sinput}
\begin{Soutput}
##        smoker
## outcome    No   Yes
##   Alive 0.686 0.761
##   Dead  0.314 0.239
##   Total 1.000 1.000
\end{Soutput}
\end{Schunk}

Notice that in the final example, conditional proportions are
calculated. From this we see that smokers were more likely to be alive
in the follow-up study. More on this in a moment.

Formula interfaces are provided for \texttt{mean()}, \texttt{median()},
\texttt{sd()}, \texttt{var()}, \texttt{cor()}, \texttt{cov()},
\texttt{quantile()}, \texttt{max()}, \texttt{min()}, \texttt{range()},
\texttt{IQR()}, \texttt{iqr()}, \texttt{fivenum()}, \texttt{prod()}, and
\texttt{sum()}. In each case we have been careful not to break behavior
of the underlying functions from \pkg{base} and \pkg{stats}.

The formula template can be extended to handle one variable or more than
two variables, but we recommend introducing it in the context of
two-variable plots and summaries. This is for several reasons: (1)
two-variable plots and numerical summaries are more ``impressive'' than
one one-variable plots and less likely to be something students can as
readily do with tools they already know, (2) working with more than one
variable from the start (correctly) suggests that the most interesting
parts of statistics involve more than one variable
\citep{Wild:RSS:2011}, and (3) the formula syntax for a single variable
makes more sense in the context of two-sided formulas than it does in
isolation.

Once the two-variable summaries are understood, we can add a third or
fourth variable with

\begin{Schunk}
\begin{Sinput}
goal( y ~ x | z, groups = mygroups, data = mydata )    # pseudo-code
\end{Sinput}
\end{Schunk}

\noindent
When plotting, \texttt{z} is used to create plots with subpanels (or
facets) and \texttt{groups} indicates overlaid layers. Each of these two
plots shows a clear difference in the distribution of births one the two
weekend days compared to the other five days of the week:

\begin{Schunk}
\begin{Sinput}
xyplot(births ~ date, groups = wday, data = Births78, type = "l")
densityplot( ~ births, groups = wday, data = Births78, auto.key = list(columns = 3))
\end{Sinput}


\begin{center}\includegraphics[width=.45\textwidth]{pruim-horton-kaplan_files/figure-latex/unnamed-chunk-9-1} \includegraphics[width=.45\textwidth]{pruim-horton-kaplan_files/figure-latex/unnamed-chunk-9-2} \end{center}

\end{Schunk}

And these plots begin to reveal a difficulty in interpretting data from
the \texttt{Whickham} data set:

\begin{Schunk}
\begin{Sinput}
densityplot( ~ age | smoker, data = Whickham, auto.key = TRUE)
densityplot( ~ age, groups = smoker, data = Whickham, auto.key = TRUE)
bwplot( age ~ smoker, data = Whickham)
\end{Sinput}


\begin{center}\includegraphics[width=.45\textwidth]{pruim-horton-kaplan_files/figure-latex/unnamed-chunk-10-1} \includegraphics[width=.45\textwidth]{pruim-horton-kaplan_files/figure-latex/unnamed-chunk-10-2} \includegraphics[width=.45\textwidth]{pruim-horton-kaplan_files/figure-latex/unnamed-chunk-10-3} \end{center}

\end{Schunk}

\noindent
The smokers were on average younger than the non-smokers.

For numerical summaries, an explanatory variable, a condition
\texttt{z}, or \texttt{groups} play essentially the same role, so each
of the following produces an equivalent result.

\begin{Schunk}
\begin{Sinput}
mean( age ~ smoker, data = Whickham)
mean( ~ age | smoker, data = Whickham)
mean( ~ age, groups = smoker, data = Whickham)
\end{Sinput}
\end{Schunk}\begin{Schunk}
\begin{Soutput}
##   No  Yes 
## 48.7 44.7
\end{Soutput}
\end{Schunk}

\noindent
This allows us to compute numerical summaries by replacing the name of
the plot with the name of the desired summary.

The one-variable template can be obtained by removing the left-hand side
from the formula in a two-variable template.

\begin{Schunk}
\begin{Sinput}
goal( ~ x, data = mydata )               # pseudo-code
\end{Sinput}
\end{Schunk}

\noindent
In the context of plotting, this makes sense since we are providing the
data for the \(x\)-axis and allowing R to compute values for the
\(y\)-axis:

\begin{Schunk}
\begin{Sinput}
histogram( ~ age, data = Whickham)
\end{Sinput}


\begin{center}\includegraphics[width=.45\textwidth]{pruim-horton-kaplan_files/figure-latex/unnamed-chunk-14-1} \end{center}

\end{Schunk}

\noindent
Numerical summaries fit this pattern by analogy (and because R formulas
are required to have a right hand side).

\begin{Schunk}
\begin{Sinput}
mean( ~ age, data = Whickham)
\end{Sinput}
\begin{Soutput}
## [1] 46.9
\end{Soutput}
\end{Schunk}

As students become familiar with the formula interface, all three forms
can be brought together into a single template:

\begin{Schunk}
\begin{Sinput}
goal( formula, data = mydata, ... )      # pseudo-code
\end{Sinput}
\end{Schunk}

\noindent
The formula template allows students to think about relationships
between and among two or more variables and to test conjectures using
graphical and numerical summaries. Having learned the formula interface
to graphical and numerical summaries early on, new users are well
prepared for modeling with \code{lm()}, \code{glm()}, and various
``test'' functions such as \texttt{t.test()} when the time comes. More
importantly, they begin early to train their minds to ask questions of
the form ``How does this depend on that (and some other things)?''.

By emphasizing the formula template, each of the following commands can
be viewed as instances of a common template, rather than as separate
things to learn.

\begin{Schunk}
\begin{Sinput}
bwplot(age ~ smoker, data = Whickham)
  mean(age ~ smoker, data = Whickham)
    sd(age ~ smoker, data = Whickham)
    lm(age ~ smoker, data = Whickham)
t.test(age ~ smoker, data = Whickham) 
\end{Sinput}
\end{Schunk}

\noindent
Similarly, by adding additional formula interfaces to \texttt{t.test()},
\texttt{binom.test()}, and \texttt{prop.test()}, and adding some
additional plot types, for one-variable situations we have

\begin{Schunk}
\begin{Sinput}
       mean( ~ age, data = Whickham)
         sd( ~ age, data = Whickham)
   favstats( ~ age, data = Whickham)
  histogram( ~ age, data = Whickham)
     t.test( ~ age, data = Whickham)   # formula interface added in mosaic
 binom.test( ~ smoker, data = Whickham)   # formula interface added in mosaic
  prop.test( ~ smoker, data = Whickham)   # formula interface added in mosaic
\end{Sinput}
\end{Schunk}

\noindent
Adding covariates to one- or two- variable graphical or numerical
summaries fits readily into the template as well.

\begin{Schunk}
\begin{Sinput}
     mean( ~ age | smoker, data = Whickham)
       sd( ~ age | smoker, data = Whickham)
histogram( ~ age | smoker, data = Whickham)
   t.test( ~ age | smoker, data = Whickham)
\end{Sinput}
\end{Schunk}

While specifying the correct formula can produce some challenges for new
users, clearly explaining the roles of each component for plotting, for
numerical summaries, and for model fitting helps demystify the
situation. Instructors have had students create and interpret bivariate
and trivariate graphical displays on the first day of class
\citep{Wang:USCOTS:2015}. We have also found that explicit, early,
low-stakes assessment of student mastery of the formula interface
greatly improves student performance. A first quiz consisting of a
single item (What is the formula template?) followed by one or two
simple pencil-and-paper quizzes asking students to write the commands to
recreate a handful of numerical and graphical summaries suffices.

\section{Working with models}\label{working-with-models}

\subsection{Visualizing distributions of random
variables}\label{visualizing-distributions-of-random-variables}

A number of functions make it simple to visualize random variables.
\texttt{plotDist()} creates displays for any distribution for which
standard d-, p-, and q- functions exist.

\begin{Schunk}
\begin{Sinput}
plotDist("norm", mean = 100, sd = 10)
plotDist("binom", size = 100, prob = 0.3)
\end{Sinput}


\begin{center}\includegraphics[width=.45\textwidth]{pruim-horton-kaplan_files/figure-latex/unnamed-chunk-20-1} \includegraphics[width=.45\textwidth]{pruim-horton-kaplan_files/figure-latex/unnamed-chunk-20-2} \end{center}

\end{Schunk}

\noindent
Tail probabilities can be highlighted using the \texttt{groups} argument
in a way that is analogous to the lattice plots above.

\begin{Schunk}
\begin{Sinput}
plotDist("chisq", df = 4, groups = x > 9, type = "h")
\end{Sinput}


\begin{center}\includegraphics[width=.45\textwidth]{pruim-horton-kaplan_files/figure-latex/unnamed-chunk-21-1} \end{center}

\end{Schunk}

\noindent
Using the \texttt{kind} argument, we can obtain other types of plots,
including cdfs and probability histograms.

\begin{Schunk}
\begin{Sinput}
plotDist("norm", mean = 100, sd = 10, kind = "cdf")
plotDist("binom", size = 100, prob = 0.3, kind = "histogram")
\end{Sinput}


\begin{center}\includegraphics[width=.45\textwidth]{pruim-horton-kaplan_files/figure-latex/unnamed-chunk-22-1} \includegraphics[width=.45\textwidth]{pruim-horton-kaplan_files/figure-latex/unnamed-chunk-22-2} \end{center}

\end{Schunk}

\noindent
Any of these plots can be overlaid onto another plot using
\texttt{add\ =\ TRUE}

\begin{Schunk}
\begin{Sinput}
favstats(~age, data = Whickham)
\end{Sinput}
\begin{Soutput}
##  min Q1 median Q3 max mean   sd    n missing
##   18 32     46 61  84 46.9 17.4 1314       0
\end{Soutput}
\begin{Sinput}
histogram(~age, data = Whickham, main = 'histogram() with added plotDist()')
plotDist("norm", params = list(mean = 46.9, sd = 17.4), add = TRUE)
\end{Sinput}


\begin{center}\includegraphics[width=.45\textwidth]{pruim-horton-kaplan_files/figure-latex/unnamed-chunk-23-1} \end{center}

\end{Schunk}

\noindent
or by using additional features of the \texttt{histogram()} function
provided in the \pkg{mosaic} package:

\begin{Schunk}
\begin{Sinput}
histogram( ~age, data = Whickham, fit = "normal", 
           main = 'histogram() with fit = "normal"')
\end{Sinput}


\begin{center}\includegraphics[width=.45\textwidth]{pruim-horton-kaplan_files/figure-latex/unnamed-chunk-24-1} \end{center}

\end{Schunk}

\noindent Several other families of distributions can be added to a
histogram in a similar way. The \texttt{fitdistr()} function from the
\CRANpkg{MASS} \citep{MASS} is used to estimate the parameters of the
distribution.

For several distributions, we provide augmented versions of the
distribution and quantile functions that assist students in
understanding what values are returned by functions like
\texttt{pnorm()} and \texttt{qnorm()}.

\begin{Schunk}
\begin{Sinput}
xpnorm(-2:2, main = "standard normal")
\end{Sinput}
\begin{Soutput}
## 
## If X ~ N(0, 1), then 
## 
##  P(X <= -2) = P(Z <= -2) = 0.0228
##      P(X <= -1) = P(Z <= -1) = 0.1587
##      P(X <=  0) = P(Z <=  0) = 0.5000
##      P(X <=  1) = P(Z <=  1) = 0.8413
##      P(X <=  2) = P(Z <=  2) = 0.9772
##  P(X >  -2) = P(Z >  -2) = 0.9772
##      P(X >  -1) = P(Z >  -1) = 0.8413
##      P(X >   0) = P(Z >   0) = 0.5000
##      P(X >   1) = P(Z >   1) = 0.1587
##      P(X >   2) = P(Z >   2) = 0.0228
\end{Soutput}
\begin{Soutput}
## [1] 0.0228 0.1587 0.5000 0.8413 0.9772
\end{Soutput}
\begin{Sinput}
xqt(0.975, df = 20, main = "t-distribution with df = 20")
\end{Sinput}
\begin{Soutput}
## [1] 2.09
\end{Soutput}


\begin{center}\includegraphics[width=.45\textwidth]{pruim-horton-kaplan_files/figure-latex/unnamed-chunk-25-1} \includegraphics[width=.45\textwidth]{pruim-horton-kaplan_files/figure-latex/unnamed-chunk-25-2} \end{center}

\end{Schunk}

\subsection{A complete formula interface for the test
functions}\label{a-complete-formula-interface-for-the-test-functions}

The \texttt{t.test()} function allows for a formula interface for
2-sample t tests, but not for 1-sample tests. Similarly,
\texttt{binom.test()} and \texttt{prop.test()} do not provide a formula
interface at all and work only from summaries of data rather than from
raw data. The \pkg{mosaic} package masks these functions to provide the
missing formula interfaces.

\begin{Schunk}
\begin{Sinput}
t.test( ~ age, data = Whickham)           # requires mosaic
t.test( age ~ smoker, data = Whickham)    # works without mosaic
t.test( ~ age | smoker, data = Whickham)  # requires mosaic
binom.test( ~ smoker, data = Whickham)    # requires mosaic
prop.test( ~ smoker, data = Whickham)     # requires mosaic
\end{Sinput}
\end{Schunk}

\subsection{Extracting the fitted
function}\label{extracting-the-fitted-function}

Modeling functions like \code{lm()} and \code{glm()} can fit a wide
range of statistical models. But functions like \code{predict()} are
challenging for new users, and constructing a useful graphical
representation of a data set together with a logistic regression fit
even more so. The \pkg{mosaic} functions \code{makeFun()},
\code{plotFun()}, and \code{plotModel()} make these things easier.

We can use \code{makeFun()} to create functions from model objects
created by \texttt{lm()} and \texttt{glm()}. These functions are
wrappers around \code{predict()}, but can be called with the standard
function semantics and plotted with \code{plotFun()}. In the example
below, we compare linear and quadratic fits to the same data.

\begin{Schunk}
\begin{Sinput}
cars.mod1 <- lm(dist ~ speed, data = cars)
cars.mod2 <- lm(dist ~ poly(speed,2), data = cars)
cars.dist1 <- makeFun(cars.mod1)
cars.dist2 <- makeFun(cars.mod2)
cars.dist2(speed = 15)
\end{Sinput}
\begin{Soutput}
##    1 
## 38.7
\end{Soutput}
\begin{Sinput}
cars.dist2(speed = 15, interval = "confidence")
\end{Sinput}
\begin{Soutput}
##    fit lwr  upr
## 1 38.7  33 44.3
\end{Soutput}
\begin{Sinput}
xyplot(dist ~ speed, data = cars, alpha = 0.4)
plotFun(cars.dist1(s) ~ s, add = TRUE, col = 2, lwd = 2)
plotFun(cars.dist2(s) ~ s, add = TRUE, col = 3, lwd = 2)
\end{Sinput}


\begin{center}\includegraphics[width=.45\textwidth]{pruim-horton-kaplan_files/figure-latex/unnamed-chunk-27-1} \end{center}

\end{Schunk}

\noindent
For logistic regression, when the response is coded as a factor, we need
to adjust things slightly when plotting because the model function
returns values between 0 and 1, but 2-level factors are coded as 1 and 2
in R.

\begin{Schunk}
\begin{Sinput}
smoker.mod <- glm(outcome ~ smoker + age, data = Whickham, family = binomial)
smoker.fun <- makeFun(smoker.mod)
smoker.fun(age = 60, smoker = "Yes")
\end{Sinput}
\begin{Soutput}
##     1 
## 0.507
\end{Soutput}
\begin{Sinput}
smoker.fun(age = 60, smoker = "No")
\end{Sinput}
\begin{Soutput}
##     1 
## 0.456
\end{Soutput}
\begin{Sinput}
xyplot(outcome ~ age, groups = smoker, data = Whickham, jitter.y = TRUE)
plotFun(1 + smoker.fun(age, smoker = "No") ~ age, col = 1, add = TRUE)
plotFun(1 + smoker.fun(age, smoker = "Yes") ~ age, col = 2, add = TRUE)
\end{Sinput}


\begin{center}\includegraphics[width=.45\textwidth]{pruim-horton-kaplan_files/figure-latex/unnamed-chunk-28-1} \end{center}

\end{Schunk}

This wrapper around \texttt{predict()} is easier for beginners to use
because (a) it returns a function to which inputs can be supplied
without creating a data frame, (b) the resulting function returns values
on the response scale by default, and (c) it back transforms a few
common transformations of the response variable, including
\texttt{log()} and \texttt{sqrt()} (and allows the user to provide a
custom value to the \texttt{transform} argument to handle other cases).

\begin{Schunk}
\begin{Sinput}
mtcars.mod <- lm(log(mpg) ~ log(wt) + factor(cyl), data = mtcars)
mileage <- makeFun(mtcars.mod)
xyplot(mpg ~ wt, data = mtcars, groups = cyl)
plotFun( mileage(w, cyl = 4) ~ w, add = TRUE, col = 1)
plotFun( mileage(w, cyl = 6) ~ w, add = TRUE, col = 2)
plotFun( mileage(w, cyl = 8) ~ w, add = TRUE, col = 3)
\end{Sinput}


\begin{center}\includegraphics[width=.45\textwidth]{pruim-horton-kaplan_files/figure-latex/unnamed-chunk-29-1} \end{center}

\end{Schunk}

For many simple models, creating a plot can be even simpler using
\texttt{plotModel()}, which also eliminates the need to manually adjust
logistic regression plots when the response is a factor. For models with
multiple predictors, we can supply a formala to indicate which predictor
we prefer to have on the x-axis.

\begin{Schunk}
\begin{Sinput}
plotModel(cars.mod2)
plotModel(smoker.mod, outcome ~ age, jitter.y = TRUE)
\end{Sinput}


\begin{center}\includegraphics[width=.45\textwidth]{pruim-horton-kaplan_files/figure-latex/unnamed-chunk-30-1} \includegraphics[width=.45\textwidth]{pruim-horton-kaplan_files/figure-latex/unnamed-chunk-30-2} \end{center}

\end{Schunk}

\noindent
The \texttt{plotModel()} function can also simplify visualization of
more complex models.

\begin{Schunk}
\begin{Sinput}
mtcars.mod2 <- lm(mpg ~ log(wt) + factor(cyl) + factor(am), data = mtcars)
plotModel(mtcars.mod2, mpg ~ wt | factor(am))
\end{Sinput}


\begin{center}\includegraphics[width=.45\textwidth]{pruim-horton-kaplan_files/figure-latex/unnamed-chunk-31-1} \end{center}

\end{Schunk}

Especially in calculus, but also when modeling in statistics, it can be
useful to create functions defined by algebraic formulas. With
\texttt{makeFun()} we can construct such functions using a formula
interface instead of using \code{function()}, if we prefer.

\begin{Schunk}
\begin{Sinput}
f <- makeFun(A + B * log(x) ~ x, A = 1, B = 1)
f
\end{Sinput}
\begin{Soutput}
## function (x, A = 1, B = 1) 
## A + B * log(x)
\end{Soutput}
\begin{Sinput}
f(2)
\end{Sinput}
\begin{Soutput}
## [1] 1.69
\end{Soutput}
\begin{Sinput}
plotFun(f(x) ~ x, xlim = c(0,3))
\end{Sinput}


\begin{center}\includegraphics[width=.45\textwidth]{pruim-horton-kaplan_files/figure-latex/unnamed-chunk-32-1} \end{center}

\end{Schunk}

\subsection{The extractor template}\label{the-extractor-template}

The use of \texttt{makeFun()} to create a function from a model
illustrates another important template: the extractor template:

\begin{Schunk}
\begin{Sinput}
object <- { some computation }
extractor(object)
\end{Sinput}
\end{Schunk}

R has many such extractors which summarise, display, or extract partial
information from an object. \texttt{print()}, \texttt{plot()}, and
\texttt{summary()} are examples of extractors that can be applied to
many types of objects. Other extractors, like \texttt{resid()} and
\texttt{fitted()} are designed to work with a much smaller set of
objects. The \pkg{mosaic} package defines several extractors including

\begin{center}
\begin{tabular}{ll}
\hline
extractor   & purpose
\\
\hline
\code{makeFun()} & extract a fitted function from a model \\
\code{rsquared()}& extract $r^2$ from a linear model \\
\code{stat()}    & extract the test statistic from a hypothesis test \\
\code{pval()}    & extract the p-value from a hypothesis test \\
\code{interval()}& extract the confidence interval from a hypothesis test \\
\code{mplot()}   & create a plot from an object \\
\hline
\end{tabular}
\end{center}

\begin{Schunk}
\begin{Sinput}
interval(t.test( ~ age, data = Whickham))      # works for any "htest" object
\end{Sinput}
\begin{Soutput}
##   mean of x lower upper level
## 1      46.9    46  47.9  0.95
\end{Soutput}
\begin{Sinput}
pval(t.test(age ~ smoker, data = Whickham))    # works for any "htest" object
\end{Sinput}
\begin{Soutput}
##  p.value 
## 2.06e-05
\end{Soutput}
\begin{Sinput}
stat(t.test(age ~ smoker, data = Whickham))    # works for any "htest" object
\end{Sinput}
\begin{Soutput}
##    t 
## 4.27
\end{Soutput}
\begin{Sinput}
rsquared(lm(age ~ smoker, data = Whickham))
\end{Sinput}
\begin{Soutput}
## [1] 0.0131
\end{Soutput}
\end{Schunk}

\subsection{mplot()}\label{mplot}

The \texttt{mplot()} function has two primary use cases: creating
diagnostic plots for lm and glm objects, and interactively creating data
visualizations using the variables in a data frame. Given a model object
as its first argument, \texttt{mplot()} provides similar diagnostic
plots to those produced via \texttt{plot()} but with two primary
differences: the user may select to use either \pkg{lattice} or
\CRANpkg{ggplot2} \citep{ggplot2} graphics instead of base graphics, and
an additional plot type is provided to visualize the confidence
intervals for the coefficients of the model.

\begin{Schunk}
\begin{Sinput}
mod <- lm(length ~ width * sex, data = KidsFeet)
mplot(mod, system = "lattice", which = 1:4)
\end{Sinput}


\begin{center}\includegraphics[width=.45\textwidth]{pruim-horton-kaplan_files/figure-latex/unnamed-chunk-34-1} \includegraphics[width=.45\textwidth]{pruim-horton-kaplan_files/figure-latex/unnamed-chunk-34-2} \includegraphics[width=.45\textwidth]{pruim-horton-kaplan_files/figure-latex/unnamed-chunk-34-3} \includegraphics[width=.45\textwidth]{pruim-horton-kaplan_files/figure-latex/unnamed-chunk-34-4} \end{center}

\end{Schunk}\begin{Schunk}
\begin{Sinput}
mplot(mod, system = "ggplot2", which = 4:7)
\end{Sinput}


\begin{center}\includegraphics[width=.45\textwidth]{pruim-horton-kaplan_files/figure-latex/unnamed-chunk-35-1} \includegraphics[width=.45\textwidth]{pruim-horton-kaplan_files/figure-latex/unnamed-chunk-35-2} \includegraphics[width=.45\textwidth]{pruim-horton-kaplan_files/figure-latex/unnamed-chunk-35-3} \includegraphics[width=.45\textwidth]{pruim-horton-kaplan_files/figure-latex/unnamed-chunk-35-4} \end{center}

\end{Schunk}

We can also use \texttt{mplot()} to visually represent the results of
\texttt{TukeyHSD()}, which has been modified so that it can be applied
directly to objects produced by \texttt{lm()}.

\begin{Schunk}
\begin{Sinput}
mplot(TukeyHSD(lm(births ~ wday, data = Births78)), order = "pval")
\end{Sinput}


\begin{center}\includegraphics[width=.45\textwidth]{pruim-horton-kaplan_files/figure-latex/unnamed-chunk-36-1} \end{center}

\end{Schunk}

\noindent
Again, there are options to create either \pkg{lattice} or \pkg{ggplot2}
plots, and the resulting plots are formatted in a way that makes them
usable in a wider range of scenarios than are those produced using
\texttt{plot()}.

A second use for \texttt{mplot()} is to create \pkg{lattice} and
\pkg{ggplot2} plots interactively within RStudio. Issuing the following
command in RStudio will bring up a plot that can be modified by making
choices interactively.

\begin{Schunk}
\begin{Sinput}
mplot(HELPrct)
\end{Sinput}
\end{Schunk}

\begin{figure}
\includegraphics{half-mplot.png}
\caption{In RStudio, \texttt{mplot()} can be used to interactively generate 
plots using variables in a data frame.}
\label{fig:mplot}
\end{figure}

\noindent
The menu (see Figure \ref{fig:mplot}) allows the user to choose either
\pkg{lattice} or \pkg{ggplot2} graphics, to select the type of plot and
the variables used, and to control a few of the most commonly used
features that modify a plot (faceting, color, legends, log-scaling,
fitting a linear model or LOESS smoother). The ``Show Expression''
button exports the command used to create the plot into the console.
From there it can be edited or copied and pasted into an R Markdown
document. This can be very useful for new users working to master the
syntax for a particular graphical display.

\section{Randomization and
Resampling}\label{randomization-and-resampling}

Resampling approaches have become increasingly important in statistical
education \citep{Tintle:TAS:2015, Hesterberg:2015}. The \pkg{mosaic}
package provides simplified functionality to support teaching inference
based on randomization tests and bootstrap methods. Our goal was to
focus attention on the important parts of these techniques (e.g., where
randomness enters in and how to use the resulting distribution) while
hiding some of the technical details involved in creating loops and
accumulating values.

\subsection{A first example}\label{a-first-example}

As a first example, we often introduce the story of the lady tasting
tea. (See \cite{Salsburg:2002} for the details of this famous story.)
But here we will test a coin to see whether it is a ``fair coin''.
Suppose we flip the coin 20 times and observe only 6 heads, how
suspicious should we be that the coin is not fair? The statistical
punchline for either the lady tasting tea or testing a coin is that we
want to compute the p-value for a binomial test via simulations rather
than using formulas for the binomial distribution or normal
approximations. But we want to do this on the first day of class, and
without using any of the jargon of the preceding sentence.

Because students do not know about sampling distributions or random
variables yet, but do understand the idea of a coin toss, we have
provided \texttt{rflip()} to simulate tossing a coin one or several
times:

\begin{Schunk}
\begin{Sinput}
rflip()
\end{Sinput}
\begin{Soutput}
## 
## Flipping 1 coin [ Prob(Heads) = 0.5 ] ...
## 
## T
## 
## Number of Heads: 0 [Proportion Heads: 0]
\end{Soutput}
\begin{Sinput}
rflip(20)
\end{Sinput}
\begin{Soutput}
## 
## Flipping 20 coins [ Prob(Heads) = 0.5 ] ...
## 
## H H T T H T H H H H T T T T T H H H T T
## 
## Number of Heads: 10 [Proportion Heads: 0.5]
\end{Soutput}
\end{Schunk}

To test a null hypothesis of a fair coin, we need to simulate flipping
20 coins many times, recording for each simulation the number of heads
that were observed. The \texttt{do()} function allows us to do just that
using the following template

\begin{Schunk}
\begin{Sinput}
do(n) * {stuff to do}             # pseudo-code
\end{Sinput}
\end{Schunk}

\noindent
where \texttt{\{stuff\ to\ do\}} is typically a single R command, but
may be something more complicated. We teach this syntax by reading it
aloud: ``Do n times \ldots{}'' For example, we can flip 20 coins three
times as follows.

\begin{Schunk}
\begin{Sinput}
do(3) * rflip(20)   # do 3 times flip 20 coins
\end{Sinput}
\begin{Soutput}
##    n heads tails prop
## 1 20    10    10 0.50
## 2 20    10    10 0.50
## 3 20    11     9 0.55
\end{Soutput}
\end{Schunk}

\noindent
Notice that \texttt{do()} (technically \texttt{cull\_for\_do()}) has
been clever about what information is stored for each group of 20 coin
tosses and that the results are returned in a data frame.

It is now a simple matter to do this many more times and use numerical
or graphical summaries to investigate how unusual it is to get so few
heads if the coin is indeed a fair coin.

\begin{Schunk}
\begin{Sinput}
Sims <- do (1000) * rflip(20)
histogram( ~ heads, data = Sims, width = 1, groups = heads <= 6)
tally ( ~(heads <= 6), data = Sims)
\end{Sinput}
\begin{Soutput}
## 
##  TRUE FALSE 
##    56   944
\end{Soutput}


\begin{center}\includegraphics[width=.45\textwidth]{pruim-horton-kaplan_files/figure-latex/unnamed-chunk-41-1} \end{center}

\end{Schunk}

\noindent
Readers familiar with \pkg{lattice}, you will notice that the
\pkg{mosaic} package also adds some additional arguments to the
\texttt{histogram()} function. Among these are \code{width} and
\code{center} which can be used to control the width and position of the
bins and are much easier for new users to master than the \code{breaks}
argument supplied by \pkg{lattice}.

\subsection{sample(), resample(), and
shuffle()}\label{sample-resample-and-shuffle}

To facilitate randomization and bootstrapping, \pkg{mosaic} extends
\texttt{sample()} to operate on data frames. The \texttt{shuffle()}
function is an alternative name for \texttt{sample()}, and
\texttt{resample()} is \texttt{sample()} with \texttt{replace\ =\ TRUE}.
With these in hand, all of the tests and confidence intervals seen in a
traditional first course in statistics can be performed using a common
outline:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Do it to your data
\item
  Do it to a randomized version of your data
\item
  Do it to lots of randomized versions of your data.
\end{enumerate}

For example, we can use randomization in place of the two-sample t test
to obtain an empirical p-value.

\begin{Schunk}
\begin{Sinput}
D <- diffmean(age ~ smoker, data = Whickham); D 
\end{Sinput}
\begin{Soutput}
## diffmean 
##    -4.02
\end{Soutput}
\begin{Sinput}
do(1) * diffmean(age ~ shuffle(smoker), data = Whickham)
\end{Sinput}
\begin{Soutput}
##   diffmean
## 1    -1.69
\end{Soutput}
\begin{Sinput}
Null.dist <- do(5000) * diffmean(age ~ shuffle(smoker), data = Whickham)
histogram( ~ diffmean, data = Null.dist, v = D)
prop( ~ (diffmean < D), data = Null.dist, format = "prop")
\end{Sinput}
\begin{Soutput}
## TRUE 
##    0
\end{Soutput}


\begin{center}\includegraphics[width=.45\textwidth]{pruim-horton-kaplan_files/figure-latex/do-diff-mean-1} \end{center}

\end{Schunk}

\noindent
None of the 5000 replications led to a difference in means as large as
the one in the original data.

It should be noted that although this is typically not done in
simulation-based introductory statistics texts, one might prefer to
calculate p-values by including the observed data in the randomization
distribution. This avoids an empirical p-value of 0 and guarantees that
the actual type I error rate will not exceed the nominal type I error
rate. This amounts to adding one to the numerator and denominator. The
\texttt{prop1()} function automates this for us

\begin{Schunk}
\begin{Sinput}
prop1( ~ (diffmean < D), data = Null.dist, format = "prop")
\end{Sinput}
\begin{Soutput}
##  TRUE 
## 2e-04
\end{Soutput}
\begin{Sinput}
1/5001
\end{Sinput}
\begin{Soutput}
## [1] 2e-04
\end{Soutput}
\end{Schunk}

\noindent
For more precise estimation of small p-values, additional replications
should be used.

The example above introduces three additional \pkg{mosaic} functions.
The \texttt{prop()} and \texttt{prop1()} functions compute the
proportion of logical vector that is (by default) \texttt{TRUE} or of a
factor that is (by default) in the first level; \texttt{diffmean()} is
similar to \texttt{diff(mean())}, but labels the result differently
(\texttt{diffprop()} works similarly for differences in proportions).

If we are interested in a confidence interval for the difference in
group means, we can use \texttt{resample()} and \texttt{do()} to
generate a bootstrap distribution in one of two ways.

\begin{Schunk}
\begin{Sinput}
Boot.dist1 <- do(1000) * diffmean(age ~ smoker, data = resample(Whickham))
Boot.dist2 <- do(1000) * diffmean(age ~ smoker, data = resample(Whickham, groups = smoker))
\end{Sinput}
\end{Schunk}

\noindent
In the second example, the resampling happens within the sex groups so
that the marginal counts for each sex remain fixed. This can be
especially important if one of the groups is small, because otherwise
some resamples might not include any observations of that group.

\begin{Schunk}
\begin{Sinput}
favstats(age ~ smoker, data = Whickham)
\end{Sinput}
\begin{Soutput}
##   smoker min Q1 median Q3 max mean   sd   n missing
## 1     No  18 32     48 65  84 48.7 18.8 732       0
## 2    Yes  18 32     45 57  84 44.7 15.3 582       0
\end{Soutput}
\begin{Sinput}
favstats(age ~ smoker, data = resample(Whickham))
\end{Sinput}
\begin{Soutput}
##   smoker min Q1 median Q3 max mean   sd   n missing
## 1     No  18 32     48 65  84 48.6 18.8 752       0
## 2    Yes  18 32     45 56  83 44.8 15.0 562       0
\end{Soutput}
\begin{Sinput}
favstats(age ~ smoker, data = resample(Whickham, groups = smoker))  # fix margins
\end{Sinput}
\begin{Soutput}
##   smoker min Q1 median Q3 max mean   sd   n missing
## 1     No  18 33   49.0 66  84 49.3 18.9 732       0
## 2    Yes  18 31   44.5 56  82 44.3 15.4 582       0
\end{Soutput}
\end{Schunk}

Using either bootstrap distribution, two simple confidence intervals can
be computed. We typically introduce percentile confidence intervals
first. A percentile confidence interval is calculated by determining the
range of a central portion of the bootstrap distribution, which can be
automated using \texttt{cdata()}. Visually inspecting the bootstrap
distribution for skew and bias is an important step to make sure the
percentile interval is not being applied in a situation where it may
perform poorly.

\begin{Schunk}
\begin{Sinput}
histogram( ~ diffmean, data = Boot.dist2, v = D)
qqmath( ~ diffmean, data = Boot.dist2)
cdata( ~ diffmean, p = 0.95, data = Boot.dist2)
\end{Sinput}
\begin{Soutput}
##       low        hi central.p 
##     -5.93     -2.30      0.95
\end{Soutput}


\begin{center}\includegraphics[width=.45\textwidth]{pruim-horton-kaplan_files/figure-latex/unnamed-chunk-47-1} \includegraphics[width=.45\textwidth]{pruim-horton-kaplan_files/figure-latex/unnamed-chunk-47-2} \end{center}

\end{Schunk}

\noindnet
Alternatively, we can compute a confidence interval based on a bootstrap
estimate of the standard error.

\begin{Schunk}
\begin{Sinput}
SE <- sd( ~ diffmean, data = Boot.dist2); SE
\end{Sinput}
\begin{Soutput}
## [1] 0.941
\end{Soutput}
\begin{Sinput}
D + c(-1,1) * 2 * SE
\end{Sinput}
\begin{Soutput}
## [1] -5.90 -2.14
\end{Soutput}
\end{Schunk}

\noindent
The primary pedagogical value of the bootstrap standard error approach
is its close connection to the standard formula-based confidence
interval methods. How to replace the constant 2 with an appropriate
value to create more accurate intervals or to allow for different
confidence levels is a matter of some subtlety \citep{Hesterberg:2015}.
The simplest method is to use quantiles of a normal distribution, but
this will undercover. Replacing the normal distribution with an
appropriate t-distribution will widen intervals and can improve
coverage, but the t-distribution is only correct in a few cases -- such
as when estimating the mean of a normal population -- and can perform
badly when the population is skewed.

Calculating simple confidence intervals can be further automated using
an extension to \texttt{confint()}.

\begin{Schunk}
\begin{Sinput}
confint(Boot.dist2, method = c("percentile", "stderr"))
\end{Sinput}
\begin{Soutput}
##       name lower upper level     method estimate margin.of.error   df
## 1 diffmean -5.93  -2.3  0.95 percentile    -4.02              NA   NA
## 2 diffmean -5.89  -2.2  0.95     stderr    -4.02            1.85 1313
\end{Soutput}
\end{Schunk}

\subsection{do() vs.~replicate()}\label{do-vs.replicate}

The usual alternative to \texttt{do()} is \texttt{replicate()}. For
simple situations, \texttt{replicate()} can also be easy to use. Each of
these stores its results in a vector rather than in a data frame, but it
otherwise very similar to the corresponding results above, although the
first stores less information.

\begin{Schunk}
\begin{Sinput}
replicate(3, rflip(20)) 
\end{Sinput}
\begin{Soutput}
## [1]  9 13 11
\end{Soutput}
\begin{Sinput}
replicate(3, diffmean(age ~ smoker, data = resample(Whickham)))
\end{Sinput}
\begin{Soutput}
## diffmean diffmean diffmean 
##    -2.04    -4.56    -5.33
\end{Soutput}
\end{Schunk}

Where \texttt{do()} really shines in simulations based on models.

\begin{Schunk}
\begin{Sinput}
do(3) * lm(shuffle(height) ~ sex + mother, Galton)
\end{Sinput}
\begin{Soutput}
## Source: local data frame [3 x 10]
## 
##   Intercept   sexM  mother sigma r.squared      F numdf dendf  .row .index
##       (dbl)  (dbl)   (dbl) (dbl)     (dbl)  (dbl) (dbl) (dbl) (int)  (dbl)
## 1      64.1 0.0356 0.04086  3.59  0.000708 0.3168     2   895     1      1
## 2      66.4 0.0869 0.00543  3.59  0.000156 0.0699     2   895     1      2
## 3      62.2 0.0175 0.07175  3.58  0.002132 0.9562     2   895     1      3
\end{Soutput}
\begin{Sinput}
replicate(3, lm(shuffle(height) ~ sex + mother, Galton))
\end{Sinput}
\begin{Soutput}
##               [,1]        [,2]        [,3]       
## coefficients  Numeric,3   Numeric,3   Numeric,3  
## residuals     Numeric,898 Numeric,898 Numeric,898
## effects       Numeric,898 Numeric,898 Numeric,898
## rank          3           3           3          
## fitted.values Numeric,898 Numeric,898 Numeric,898
## assign        Integer,3   Integer,3   Integer,3  
## qr            List,5      List,5      List,5     
## df.residual   895         895         895        
## contrasts     List,1      List,1      List,1     
## xlevels       List,1      List,1      List,1     
## call          Expression  Expression  Expression 
## terms         Expression  Expression  Expression 
## model         List,3      List,3      List,3
\end{Soutput}
\end{Schunk}

\noindent
The results returned by \texttt{do()} are stored in a tidy data frame
and include the components of the model most likely to be of interest.
In contrast, \texttt{replicate()} returns an object that is inscrutible
and unusable for most beginners.

\section{Some additional features of the mosaic
package}\label{some-additional-features-of-the-mosaic-package}

\subsection{Handling missing data}\label{handling-missing-data}

When there are missing values, the numerical summary functions in
\pkg{base} and \pkg{stats} return results that may surprise and mystify
new users.

\begin{Schunk}
\begin{Sinput}
mean( ~ dayslink, data = HELPmiss)
\end{Sinput}
\begin{Soutput}
## [1] NA
\end{Soutput}
\end{Schunk}

\noindent
While there are workarounds using options to functions to drop values
that are missing before performing the computation, these may be
intimidating to new users.

\begin{Schunk}
\begin{Sinput}
mean( ~ dayslink, data = HELPmiss, na.rm = TRUE)
\end{Sinput}
\begin{Soutput}
## [1] 257
\end{Soutput}
\end{Schunk}

We offer two other solutions to this situation. Our favorite is the
\texttt{favstats()} function which computes a set of useful numerical
summaries on the non-missing values and also reports the number of
missing values.

\begin{Schunk}
\begin{Sinput}
favstats( ~ dayslink, data = HELPmiss)
\end{Sinput}
\begin{Soutput}
##  min Q1 median  Q3 max mean  sd   n missing
##    2 75    363 365 456  257 151 447      23
\end{Soutput}
\end{Schunk}

The second solution is to change the default behavior of \texttt{na.rm}
using \texttt{options()}. This will, of course, only affect the
\pkg{mosaic} versions of these functions.

\begin{Schunk}
\begin{Sinput}
options(na.rm = TRUE)
mean(~ dayslink, data = HELPmiss)
\end{Sinput}
\begin{Soutput}
## [1] 257
\end{Soutput}
\begin{Sinput}
with(HELPmiss, base::mean(dayslink))
\end{Sinput}
\begin{Soutput}
## [1] NA
\end{Soutput}
\end{Schunk}

\noindent
Users also have the option of changing the default for \texttt{na.rm}
back if they like.

\begin{Schunk}
\begin{Sinput}
options(na.rm = NULL)
mean(~ dayslink, data = HELPmiss)
\end{Sinput}
\begin{Soutput}
## [1] NA
\end{Soutput}
\end{Schunk}

\subsection{Inspecting a data frame}\label{inspecting-a-data-frame}

Summaries of all variables in a data frame can be obtained using
\texttt{inspect()}. For quantitative variables, the results of
\texttt{favstats()} are displayed. Other summaries are provided for
categorical and time variables.

\begin{Schunk}
\begin{Sinput}
inspect(Births78)
\end{Sinput}
\begin{Soutput}
## 
## categorical variables:  
##   name   class levels   n missing                                  distribution
## 1 wday ordered      7 365       0 Sun (14.5%), Mon (14.2%), Tues (14.2%) ...   
## 
## quantitative variables:  
##        name   class  min   Q1 median   Q3   max mean  sd   n missing
## 1    births integer 7135 8554   9218 9705 10711 9132 818 365       0
## 2 dayofyear integer    1   92    183  274   365  183 106 365       0
## 
## time variables:  
##   name   class      first       last min_diff max_diff   n missing
## 1 date POSIXct 1978-01-01 1978-12-31        1        1 365       0
\end{Soutput}
\end{Schunk}

\subsection{Additional high-level lattice
plots}\label{additional-high-level-lattice-plots}

The \pkg{mosaic} package provides several new high-level \pkg{lattice}
plots, including \texttt{bargraph()}, \texttt{dotPlot()},
\texttt{freqpolygon()}, \texttt{ashplot()}, \texttt{xqqmath()}, and
\texttt{plotPoints()}.

\begin{Schunk}
\begin{Sinput}
bargraph( ~ smoker, data = Whickham, main = "bargraph()")
dotPlot( ~ age, data = Whickham, width = 1, main = "dotPlot()")
\end{Sinput}


\begin{center}\includegraphics[width=.45\textwidth]{pruim-horton-kaplan_files/figure-latex/unnamed-chunk-58-1} \includegraphics[width=.45\textwidth]{pruim-horton-kaplan_files/figure-latex/unnamed-chunk-58-2} \end{center}

\end{Schunk}\begin{Schunk}
\begin{Sinput}
freqpolygon( ~ age, data = Whickham, width = 5, main = "freqpolygon()")
ashplot( ~ age, data = Whickham, width = 5, main = "ashplot()")
\end{Sinput}


\begin{center}\includegraphics[width=.45\textwidth]{pruim-horton-kaplan_files/figure-latex/unnamed-chunk-59-1} \includegraphics[width=.45\textwidth]{pruim-horton-kaplan_files/figure-latex/unnamed-chunk-59-2} \end{center}

\end{Schunk}\begin{Schunk}
\begin{Sinput}
xqqmath( ~ age, data = Whickham, main = "xqqmath()")
plotPoints(length ~ width, data = KidsFeet, main = "plotPoints()")
\end{Sinput}


\begin{center}\includegraphics[width=.45\textwidth]{pruim-horton-kaplan_files/figure-latex/unnamed-chunk-60-1} \includegraphics[width=.45\textwidth]{pruim-horton-kaplan_files/figure-latex/unnamed-chunk-60-2} \end{center}

\end{Schunk}

The \texttt{bargraph()} function eliminates the need to first summarize
the data before constructing a plot with \texttt{barplot()} and makes
creating these plots from raw data simpler. The dot plots produced by
\texttt{dotPlot()} are quite different from the Cleveland-style dot
plots produced by \texttt{dotplot()}. The former are essentially
histograms made of stacked dots and can be seen in many introductory
statistics texts. They are also useful for producing plots from which
students can quickly estimate p-values by counting dots in the tail of a
randomization distribution. Frequency polygons and ASH plots (average
shifted histograms) are less common, but share many features in common
with density plots and are easier to explain to students. The main
motivation for \texttt{plotPoints()} is the abbility to use it to create
additional layers on an existing plot with the option
\texttt{add\ =\ TRUE}, otherwise \texttt{xyplot()} would suffice.

\subsection{Basic choropleth maps}\label{basic-choropleth-maps}

We provide functionality for creating basic choropleth maps:
\texttt{mUSMap()} and \texttt{mWorldMap()} provide simple ways to
construct choropleth maps of states in the US or countries in the world,
and \texttt{makeMap()} allows users to provide their own map data.

\begin{Schunk}
\begin{Sinput}
USArrests <- USArrests %>% mutate(state = row.names(USArrests))
mUSMap(USArrests, key = "state", fill = "UrbanPop")
\end{Sinput}


\begin{center}\includegraphics[width=.45\textwidth]{pruim-horton-kaplan_files/figure-latex/unnamed-chunk-61-1} \end{center}

\end{Schunk}

\subsection{Work-arounds for unfortunate name
collisions}\label{work-arounds-for-unfortunate-name-collisions}

The \pkg{mosaic} package depends on \pkg{lattice} and \pkg{ggplot2} so
that plots can be made using either system whenever the \pkg{mosaic}
package is attached. It also depends on \CRANpkg{dplyr} \citep{dplyr},
but for a different reason. The functions in \pkg{dplyr} implement a
``less volume, more creativity'' approach to data transformation and we
encourage its use along side \pkg{mosaic}. Unfortunatley, there are
several function names -- most notably \texttt{do()} and
\texttt{tally()} -- that exist in both packages. After the release of
\pkg{dplyr} we modified the functions in \pkg{mosaic} so that the two
packages can coexist amicably as long as \pkg{mosaic} comes before
\pkg{dplyr} in the search path.

\subsection{But wait, there's more}\label{but-wait-theres-more}

Table \ref{tbl:otherstuff} lists some additional functions in the
\pkg{mosaic} package not highlighted above.\\
The package also contains three templates for creating R Markdown
documents in RStudio. Each ensures that the \pkg{mosaic} package is
attached, sets the default theme for \pkg{lattice} graphics to
\texttt{theme.mosaic()}, chooses a somewhat smaller default size for
graphics, and includes a comment reminding users to attach any packages
they intend to use. The ``fancy'' template demonstrates several features
of R Markdown, and the ``plain'' templates allow users to start with a
clean slate. See \cite{Baumer:RMarkdown:2014} for a discussion of how R
Markdown can be used in statistics courses.

\begin{table}
\begin{tabular}{lp{4in}}
\toprule
function & uses
\\
\midrule
\texttt{CIsim()} & demonstrate coverage rates of confidence intervals.
\\
\texttt{statTally()} & investigate test statistics and their empirical distributions.
\\
\texttt{panel.lmbands()} & add confidence and prediction bands to scatter plots.
\\
\texttt{ladd()} & simplified layering in \pkg{lattice} plots.
\\
\texttt{xchisq.test()} & an extension to \texttt{chisq.test()} that prints a table including
observed and expected counts, contribution to the chi-squared statistics and residuals.
\\
\texttt{zscore()} & convert a numeric vector into z-scores.
\\
\texttt{D()}, \texttt{antiD()} & derivative and antiderivative operators that take a function
as input and return a function.   For simple functions, the operations are done symbolically.
\\
\texttt{col.mosaic()} & a \pkg{lattice} theme with colors that project better than the 
\pkg{lattice} defaults.
\\
\texttt{dot()}, \texttt{project()}, \texttt{vlength()} & linear algebra on vectors.
\\
\texttt{ediff()} & like \texttt{diff()}, but the returned vector is padded with \texttt{NA}s
so that the length is the same as the input vector.
\\
\texttt{SAD()}, \texttt{MAD()} & all pairs sum and mean of absolute differences
\\
\texttt{rgeo()} & randomly sample latitidue, longitude pairs uniformly over the globe
\\
\texttt{googleMap()} & show google maps in a browser.  Together with \texttt{rgeo()}, this can be 
used to view maps of randomly selected points on the globe.  See \cite{RoadlessAmerica}
for an example of how this can be used for a classroom activity.
\\
\bottomrule
\end{tabular}
\caption{Some additional functions in the \pkg{mosaic} package.}
\label{tbl:otherstuff}
\end{table}

\section{Discussion}\label{discussion}

\subsection{Advantages of the mosaic
approach}\label{advantages-of-the-mosaic-approach}

One of the keys to successfully empowering students to think with data
is providing them both a conceptual framework that allows them to know
what to look for and how to interpret what they find, and a
computational toolbox that allows them to do the looking. The approach
made possible with the \pkg{mosaic} package simplifies the transition
from thinking to computing by reducing the number of computational
templates students learn so that cognitive effort can be spent
elsewhere, and by having those templates reflect, support, and deepen
the underlying thinking \citep{Grolemund:ISR:2014}.

Because of the connection between conceptual understanding and these
computational tools, the use of R can also help reveal misunderstandings
that might otherwise go unnoticed. For example, if a student attempts to
use \texttt{t.test()} or to create a histogram using a categorical
variable, the student will receive error or warning messages that are an
indication that either the student does not understand the current data
set or still has confusion regarding what it means for a variable to be
categorical or continuous and which operations are suited for each kind
of variable. We encourage students to make sure they can answer two
important questions before attempting to issue a command in R:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  What do I want the computer to do for me?
\item
  What does it need to know in order to do that?
\end{enumerate}

If these two questions can be answered clearly and correctly, then the
student's primary issue is one of creating the correct R code. If they
cannot, then the problem lies elsewhere. In our experience, students who
can consistently answer these two questions have relatively little
trouble translating the answers into R code using the commands we teach.

For students who take additional courses after the first course, R has
the capability to support the increasing complexity of the data and
analyses students encounter in subsequent courses and research projects.
Eventually, students will need to learn more about the structure of R as
a language, the types of objects it supports, and alternative ways of
approaching the same task. But early on, it is more important that
students can successfully and independently exercise computational and
statistical creativity.

\subsection{Challenges of using R in introductory
courses}\label{challenges-of-using-r-in-introductory-courses}

But using R is not without some challenges. The first challenge is to
get all of the students up and running with R. The use of an RStudio
server allows an institution or instructor to install and configure R
and its packages and students to work within a web browser, essentially
eliminating the start-up costs for the students.\\
Otherwise, instructors must assist students as they navigate
installation of R and whichever additional packages are required.

Once students have access to R, the \pkg{mosaic} package reduces, but
does not eliminate, the amount of syntax students need to learn. It is
important to emphasize the similarity among commands within a template,
to remind students that R is case sensitive, to show them how to take
advantage of short cuts like tab completion and code history navigation,
and to explicitly teach students how to interpret some of the most
common R error messages. This goes a long way toward smoothing the
transition to a command line interface that is not as forgiving as
Google search, which may be many students' only other experience with a
command line interface.

In our experience, the most commonly occuring struggles for students
using \pkg{mosaic} are

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  General anxiety over typing commands.

  Although students are very familiar with using computers and
  computerized devices like smart phones, many of them have little
  experience typing commands that require following syntax rules. The
  ``Less Volume, More Creativity'' approach helps with this, by reducing
  the volume, but it remains important to highlight repeatedly the
  similarities among commands and to help students learn to understand
  the most common error messages R produces so that they can quickly,
  easily, and comfortably recover from innevitable typing errors.\\
  Even if a class does not typically meet in a computer laboratory or
  take advantage of studetn laptops, it can be useful to arrange some
  sessions early in the course where students are using RStudio while
  someone is there to quickly help them when they get stuck. Avoiding
  frustration in students' early experience with R goes a long way in
  overcoming anxiety.

  As a bonus instructional method, the authors make frequent typing
  mistakes in front of the class. While we could not avoid this if we
  tried, it does serve to demonstrate both how to recover from errors
  and that nothing drastic has happened when an error message is
  displayed.

  One big advantage of the command line interface is that it is much
  easier to help students by email or in a discussion forum. Encourage
  students to copy both their commands and the error messages or output
  that were produced.\\
  Even better, have them share their work in the form of an R Markdown
  file. We find students are much more capable of doing this than they
  are of correctly describing the chain of events they initiated in a
  menu-driven system.\\
  (It is also much easier to give detailed instructions and examples.)
\item
  Confusion over the tilde (\texttt{\textasciitilde{}}).

  The tilde is a small symbol, easily overlooked on the screen or on
  paper (or mistaken for \texttt{-}), so students will sometimes omit
  it, or put it where it doesn't belong. For several of our functions,
  we allow \texttt{x} in place of \texttt{\textasciitilde{}\ x} to help
  ease the pain of mistyping things. But we recommend that instructors
  teach the use of \texttt{\textasciitilde{}} in all situations. A
  similar thing occurs with explicitly naming the \texttt{data}
  argument, which is not required for the \pkg{lattice} functions, but
  is for several other functions. Teaching the forms that work in all
  contexts is easier than teaching which contexts allow which forms.

  As a visual aid, we recommend surrounding the
  \texttt{\textasciitilde{}} with a space on either side, even in
  1-sided formulas.
\item
  Difficulty in setting up the R environment

  This is all but eliminated when using and RStudio server, but in
  situations where instructors prefer a local R installation for each
  student, there are often a few issues involved in getting all students
  up and running. Installation of R and RStudio is straightforward, but
  one should make sure that students all have the latest version of
  each. To use the \pkg{mosaic} package, a number of additional packages
  must be installed. We recommend beginning with

  \begin{Schunk}
  \begin{Sinput}
  update.packages()
  \end{Sinput}
  \end{Schunk}

  or the equivalent operation from the RStudio Packages tab to make sure
  all packages currently on the system are up to date. In most cases,

  \begin{Schunk}
  \begin{Sinput}
  install.packages("mosaic")
  \end{Sinput}
  \end{Schunk}

  (again, this can also be done via the Packages tab in RStudio) will
  take care of the rest. But ocassionally some package will not install
  correctly on a particular student's computer. Installing that package
  directly rather than as part of the dependencies of \pkg{mosaic} often
  solves this problem or at least provides a useful diagnostic regarding
  what the problem might be.
\end{enumerate}

\subsection{Efficiency Issues}\label{efficiency-issues}

For applications where speed is of utmost importance, the \pkg{mosaic}
wrappers may not be the optimal approach. For the numerical summary
functions, the \pkg{mosaic} versions cannot be faster than their
counterparts in \pkg{base} or \pkg{stats} (because eventually they call
the underlying functions) and may be noticeable slower in contexts where
they are called many times. In particular, using the formula interface
requires parsing the formula and creating a new object to contain the
data described by the formula. On the other hand, for aggregated
numerical summaries, the loss in performance may represent a small price
to pay for the simplified syntax.

Similarly, using \texttt{do()} comes at a price, although here the the
increased computation time has more to do with the extra work involved
in culling the objects and reformatting the results. The looping itself
is as fast as using \texttt{replicate()} -- indeed the underlying code
is very similar -- and can be faster when the \CRANpkg{parallel} package
is attached; even on a laptop with a single quad-core processor, the
speed-up is noticible.

\subsection{Be selective}\label{be-selective}

Over the years we have been developing the \pkg{mosaic} package, it has
grown to the point that it now contains much more than a minimally
sufficient set of commands for an introductory course. While we have
attempted to give some sense of the scope of the package in this
article, we advise instructors to use things selectively, keeping in
mind their students and the goals for the course. What may represent
just the right tool in one setting may be too much in another. Of
course, the same advice holds for using functions from other packages as
well. The instructor's temptation is always to do too much, forgetting
the cognitive burden this can place on students. Less volume and more
creativity will at times pull in opposite directions, and a skilled
instructor must determine the appropriate balance for each setting.

\section{Acknowledgements}\label{acknowledgements}

Partial support for this work was provided by the National Science
Foundation DUE 0920350 (Project MOSAIC). We thank Xiaofei (Susan) Wang
and the reviewers for helpful comments and suggestions, and all of the
users of the \pkg{mosaic} package who have provided use feedback on
their experience and offered suggestions for improvement.

\bibliography{pruim-horton-kaplan}

\address{%
Randall Pruim\\
Calvin College\\
Department of Mathematics and Statistics\\ 3201 Burton St SE\\ Grand Rapids, MI 49546\\
}
\href{mailto:rpruim@calvin.edu}{\nolinkurl{rpruim@calvin.edu}}

\address{%
Daniel T Kaplan\\
Macalester College\\
Deptartment of Mathematics and Computer Science\\ 1600 Grand Avenue\\ St.~Paul, MN 55105 USA\\
}
\href{mailto:dtkaplan@macalester.edu}{\nolinkurl{dtkaplan@macalester.edu}}

\address{%
Nicholas J Horton\\
Amherst College\\
Department of Mathematics and Statistics\\ PO Box 5000 AC \#2239\\ Amherst, MA 01002-5000\\
}
\href{mailto:nhorton@amherst.edu}{\nolinkurl{nhorton@amherst.edu}}

