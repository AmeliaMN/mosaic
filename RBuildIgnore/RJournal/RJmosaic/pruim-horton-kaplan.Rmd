---
title: The mosaic package&#58; helping students to 'think with data' using R
author:
  - name: Randall Pruim
    affiliation: Calvin College
    address:
    - Department of Mathematics and Statistics
    - 3201 Burton St SE
    - Grand Rapids, MI 49546
    email:  rpruim@calvin.edu
  - name: Daniel T Kaplan
    affiliation: Macalester College
    address:
    - Deptartment of Mathematics and Computer Science
    - 1600 Grand Avenue 
    - St. Paul, MN 55105 USA 
    email:  dtkaplan@macalester.edu
  - name: Nicholas J Horton
    affiliation: Amherst College
    address:
    - Department of Mathematics and Statistics
    - PO Box 5000  AC \#2239
    - Amherst, MA 01002-5000
    email:  nhorton@amherst.edu
abstract: >
  The mosaic package provides a simplified and systematic introduction to the core functionality related to descriptive statistics, visualization,  modeling, and simulation-based inference required in first and second courses in  statistics. This introduction to the package describes some of the guiding principles  behind the design of the package and provides illustrative examples of several of the most  important functions it implements.  These can be combined to help students  ``think with data" using R in their early course work,  starting with simple, yet powerful, declarative commands.


preamble: >
  % Any extra latex you need in the preamble
output: rticles::rjournal_article
---

```{r, include = FALSE}
library(mosaic)
knitr::opts_chunk$set(
  fig.width = 4.5, fig.height = 3, 
  out.width = ".45\\textwidth",
  fig.show = "hold", fig.align = "center",
  cache = TRUE,
  comment = "##"
)
options(digits = 3)
options(width = 80)
trellis.par.set(theme = col.mosaic())
# trellis.par.set(fontsize = list(text = 8, points = 5))
set.seed(1234)
mytheme <- theme_minimal() 
```

# Motivation

Many have argued that 
in order to make sense of the increasingly rich data that is
available to them,
students need additional facility to express statistical computations (e.g., 
\cite{NolanTempleLang:2010, Ridgway:2015, HortonBaumerWickham:2015}).
To be able to "think with data" (as coined by Diane Lambert of Google), students
need tools for data management, exploratory analysis,
visualization, and modeling.  Yet many students enter statistics courses
with little or no computational experience.
Our students have demonstrated that it is feasible to
integrate computing into our curricula early and often,
in a way that provides students with success, confidence, and room to grow.


# A guiding principle: Less volume, more creativity

The \CRANpkg{mosaic} \citep{mosaic} package originated in early attempts by 
each of the authors to 
ease new users into using R, primarily in the context of 
undergraduate statistics courses, and, in one case, also in calculus.
One of the guiding principles behind the development of the \pkg{mosaic} package
has been "Less volume, more creativity".  Beginners are easily overwhelmed by the 
scope of R and its many packages.  Often there are multiple ways to accomplish the 
same task, and authors of the many packages are not required to follow any particular
style guidelines.

Early on in the development of \pkg{mosaic}, we decided to
reduce the number of commands (R functions) and, more importantly, 
the number of code templates (general schemes that unify the usage of 
several functions) that users would need to know to as few as possible,
while still providing them with substantial power to be creative within the
templates provided.  Choosing a handful of code templates that unify the 
approach to using many different functions greatly reduces the cognitive
load for new users.

To successfully implement a "less volume, more creativity" approach, one must decide
which tasks are most important to accomplish.  
The key tasks we wanted our students to master included

  1. Graphical summaries of data, including multi-variable summaries;
  2. Numerical summaries of data, including multi-variable summaries;
  3. The construction, visualization, and interpretation of models  (single
  variable distribution models, the usual 1- and 2-sample inference procedures,
  linear regression, ANOVA, logistic regression, etc.); and 
  4. Simulation-based inference.

A one-page list of commands that are more than sufficient for a first course, originally
presented as part of a roundtable discussion at the Joint Statistics Meetings \citep{Pruim:MinimalR:2011}
now appears as a vignette in the package, along with some additional material on the 
less volume, more creativity approach.

# The formula template

We knew from the outset that we wanted students to be able to create
graphical and numerical summaries of data, to fit various models
and to perform inference procedures (items 1--3 in our list above).  
Because of these goals, 
our most important template makes use of a "formula interface" that is already
used by important R functions like \code{t.test()}, \code{lm()},
and the plotting functions in \CRANpkg{lattice} \citep{lattice}. 

We typically introduce the formula template in the context of exploring 
two variables as 

```{r, eval = FALSE}
goal( y ~ x, data = mydata, ... )    # pseudo-code for the formula template
```
\noindent
Those familiar with R will recognize this as the template already used by functions
such as `lm()` and the \pkg{lattice} plotting functions.  The \pkg{mosaic} package extends
this template to numerical summaries and provides some additional features
for plotting and fitting models.

For a plot, `goal` names the type of plot, `y` and `x` name the variables to be 
mapped to the vertical and horizontal axes, `mydata` is the data frame in 
which these variables are found, and `...` can contain additional options that
further refine the plot.
This template allows us to create, for example, scatterplots and side-by-side 
box plots using \pkg{lattice} functions.  Here we illustrate using the `Births78`
data set, which records the number of live births
in the United States for each day of 1978.

```{r}
library(mosaic) 
xyplot(births ~ date, data = Births78)
```
```{r}
bwplot(births ~ wday, data = Births78) 
bwplot(wday ~ births, data = Births78, pch = "|")  # a more common way to show median
```
\noindent
Using the \pkg{mosaic} package, this same template can be used to calculate numerical summaries.
```{r}
mean(births ~ wday, data = Births78)
sd(births ~ wday, data = Births78)
favstats(births ~ wday, data = Births78)
```
\noindent
These sorts of aggregated numerical summaries can be calculated in other ways, but we 
find the alternatives more difficult for beginners because they follow entirely different
syntax templates from the corresponding plots even though essentially the same information 
is being communicated to R.

```{r}
with(Births78, aggregate(births, FUN = mean, by = list(wday)))
with(Births78, tapply(births, wday, mean))
```

We introduced the `tally()` function for counting categorical variables.  We illustrate 
its use with another data set from \CRANpkg{mosaicData} \citep{mosaicData}.
`Whickham` contains data from a UK study that enrolled subjects in 1972-74 and conducted 
a follow-up 20 years later.
```{r}
tally(outcome ~ smoker, data = Whickham)
tally(outcome ~ smoker, data = Whickham, margins = TRUE)
tally(outcome ~ smoker, data = Whickham, margins = TRUE, format = "proportion")
```
Notice that in the final example, conditional proportions are calculated.  From this we see
that smokers were more likely to be alive in the follow-up study.  More on this in a moment.

Formula interfaces are provided for 
`mean()`, `median()`, 
`sd()`, `var()`, `cor()`, `cov()`,
`quantile()`, 
`max()`, `min()`, `range()`, 
`IQR()`, `iqr()`, `fivenum()`,
`prod()`, and `sum()`.
In each case we have been careful not to break behavior of the underlying functions from
\pkg{base} and \pkg{stats}.

The formula template can be extended to handle one variable or more than two variables,
but we recommend introducing it in the context of two-variable plots and summaries.
This is for several reasons: (1) two-variable plots and numerical summaries are more
"impressive" than one one-variable plots and less likely to be something students can as 
readily do with tools they already know, 
(2) working with more than one variable from the start (correctly) suggests
that the most interesting parts of statistics involve more than one variable \citep{Wild:RSS:2011},
and 
(3) the formula syntax for a single variable makes more sense in the context of two-sided
formulas than it does in isolation.

Once the two-variable summaries are understood, we can add a third or fourth variable with
```{r, eval = FALSE}
goal( y ~ x | z, groups = mygroups, data = mydata )    # pseudo-code
```
\noindent
When plotting, `z` is used to create plots with subpanels (or facets) and `groups` indicates
overlaid layers.  Each of these two plots shows a clear difference in the distribution of 
births one the two weekend days compared to the other five days of the week:
```{r}
xyplot(births ~ date, groups = wday, data = Births78, type = "l")
densityplot( ~ births, groups = wday, data = Births78, auto.key = list(columns = 3))
```
And these plots begin to reveal a difficulty in interpretting data from the `Whickham` data set:
```{r}
densityplot( ~ age | smoker, data = Whickham, auto.key = TRUE)
densityplot( ~ age, groups = smoker, data = Whickham, auto.key = TRUE)
bwplot(age ~ smoker, data = Whickham)
```
\noindent
The smokers were on average younger than the non-smokers.

For numerical summaries, an explanatory variable, a condition `z`, or `groups` play 
essentially the same role, so each of the following produces an equivalent result.

```{r, results = "hide"}
mean(age ~ smoker, data = Whickham)
mean( ~ age | smoker, data = Whickham)
mean( ~ age, groups = smoker, data = Whickham)
```
```{r, echo = FALSE}
mean(age ~ smoker, data = Whickham)
```

\noindent
This allows us to compute numerical summaries by replacing the name of the plot with 
the name of the desired summary.

The one-variable template can be obtained by removing the left-hand side from the formula
in a two-variable template.
```{r, eval = FALSE}
goal( ~ x, data = mydata )               # pseudo-code
```
\noindent
In the context of plotting, this makes sense since we are providing the data for the 
$x$-axis and allowing R to compute values for the $y$-axis:
```{r}
histogram( ~ age, data = Whickham)
```
\noindent
Numerical summaries fit this pattern by analogy (and because R formulas are required to
have a right hand side).
```{r}
mean( ~ age, data = Whickham)
```

As students become familiar with the formula interface,
all three forms can be brought together into a single template:

```{r, eval = FALSE}
goal( formula, data = mydata, ... )      # pseudo-code
```
\noindent
The formula template allows students to 
think about relationships between and among two or more variables and
to test conjectures using graphical and numerical summaries.
Having learned the formula interface to graphical and numerical
summaries early on, new users are well prepared for modeling with
\code{lm()}, \code{glm()}, and various "test" functions such as
`t.test()` when the time comes.  More importantly, they begin early to train their minds
to ask questions of the form "How does this depend on that (and some other things)?". 

By emphasizing the formula template, each of the following commands can be 
viewed as instances of a common template, rather than as separate things 
to learn. 


```{r, tidy = FALSE, eval = FALSE}
bwplot(age ~ smoker, data = Whickham)
  mean(age ~ smoker, data = Whickham)
    sd(age ~ smoker, data = Whickham)
    lm(age ~ smoker, data = Whickham)
t.test(age ~ smoker, data = Whickham) 
```

\noindent
Similarly, by adding additional formula interfaces to `t.test()`,
`binom.test()`, and `prop.test()`, and adding some additional 
plot types, for one-variable situations we have 

```{r, tidy = FALSE, eval = FALSE}
       mean( ~ age, data = Whickham)
         sd( ~ age, data = Whickham)
   favstats( ~ age, data = Whickham)
  histogram( ~ age, data = Whickham)
     t.test( ~ age, data = Whickham)   # formula interface added in mosaic
 binom.test( ~ smoker, data = Whickham)   # formula interface added in mosaic
  prop.test( ~ smoker, data = Whickham)   # formula interface added in mosaic
```

\noindent
Adding covariates to one- or two- variable graphical or numerical summaries
fits readily into the template as well.
```{r, tidy = FALSE, eval = FALSE}
     mean( ~ age | smoker, data = Whickham)
       sd( ~ age | smoker, data = Whickham)
histogram( ~ age | smoker, data = Whickham)
   t.test( ~ age | smoker, data = Whickham)
```

While specifying the correct formula can produce some challenges for new users, 
clearly explaining the roles of each component for plotting, 
for numerical summaries, and for model fitting helps demystify the situation.
Instructors have had students create and interpret bivariate and trivariate graphical
displays on the first day of class \citep{Wang:USCOTS:2015}.
We have also found that explicit, early, low-stakes assessment of student mastery
of the formula interface greatly improves student performance.  A first quiz
consisting of a single item (What is the formula template?) followed by one or two
simple pencil-and-paper quizzes asking students to write the commands to recreate
a handful of numerical and graphical summaries suffices.


# Working with models

## Visualizing distributions of random variables

A number of functions make it simple to visualize random variables.  `plotDist()` creates
displays for any distribution for which standard d-, p-, and q- functions exist.
```{r}
plotDist("norm", mean = 100, sd = 10)
plotDist("binom", size = 100, prob = 0.3)
```
\noindent
Tail probabilities can be highlighted using the `groups` argument in a way that is analogous
to the lattice plots above.
```{r}
plotDist("chisq", df = 4, groups = x > 9, type = "h")
```
\noindent
Using the `kind` argument, we can obtain other types of plots, including cdfs and 
probability histograms.
```{r}
plotDist("norm", mean = 100, sd = 10, kind = "cdf")
plotDist("binom", size = 100, prob = 0.3, kind = "histogram")
```
\noindent
Any of these plots can be overlaid onto another plot using `add = TRUE`
```{r, fig.keep = 'last'}
favstats( ~ age, data = Whickham)
histogram( ~ age, data = Whickham, main = 'histogram() with added plotDist()')
plotDist("norm", params = list(mean = 46.9, sd = 17.4), add = TRUE)
```
\noindent
or by using additional features of the `histogram()` function provided in the \pkg{mosaic} package:
```{r}
histogram( ~ age, data = Whickham, fit = "normal", 
           main = 'histogram() with fit = "normal"')
```
\noindent Several other families of distributions can be added to a histogram in a similar way.
The `fitdistr()` function from the \CRANpkg{MASS} \citep{MASS} is used to estimate the parameters of the 
distribution.

For several distributions, we provide augmented versions of the distribution and 
quantile functions that assist students in understanding what values are returned
by functions like `pnorm()` and `qnorm()`.
```{r}
xpnorm(-2:2, main = "standard normal")
xqt(0.975, df = 20, main = "t-distribution with df = 20")
```

## A complete formula interface for the test functions

The `t.test()` function allows for a formula interface for 2-sample t tests, but not for 1-sample tests.
Similarly, `binom.test()` and `prop.test()` do not provide a formula interface at all and work only
from summaries of data rather than from raw data.  The \pkg{mosaic}
package masks these functions to provide the missing formula interfaces.

```{r, eval = FALSE}
t.test( ~ age, data = Whickham)           # requires mosaic
t.test(age ~ smoker, data = Whickham)     # works without mosaic
t.test( ~ age | smoker, data = Whickham)  # requires mosaic
binom.test( ~ smoker, data = Whickham)    # requires mosaic
prop.test( ~ smoker, data = Whickham)     # requires mosaic
```

## Extracting the fitted function

Modeling functions like \code{lm()} and \code{glm()} can fit a wide range of 
statistical models.  But functions like \code{predict()} are challenging for new 
users, and constructing a useful graphical representation of a data set together 
with a logistic regression fit even more so.  The \pkg{mosaic} functions \code{makeFun()},
\code{plotFun()}, and \code{plotModel()} make these things easier.

We can use \code{makeFun()} to create functions from
model objects created by `lm()` and `glm()`.  These functions are 
wrappers around \code{predict()}, but can be called with the standard
function semantics and plotted with \code{plotFun()}.
In the example below, we compare linear and quadratic fits to the same data.
```{r, fig.keep = "last", message = FALSE}
cars.mod1 <- lm(dist ~ speed, data = cars)
cars.mod2 <- lm(dist ~ poly(speed,2), data = cars)
cars.dist1 <- makeFun(cars.mod1)
cars.dist2 <- makeFun(cars.mod2)
cars.dist2(speed = 15)
cars.dist2(speed = 15, interval = "confidence")
xyplot(dist ~ speed, data = cars, alpha = 0.4)
plotFun(cars.dist1(s) ~ s, add = TRUE, col = 2, lwd = 2)
plotFun(cars.dist2(s) ~ s, add = TRUE, col = 3, lwd = 2)
```

\noindent
For logistic regression, when the response is coded as a factor, we need to adjust things 
slightly when plotting because the model function returns values between 0 and 1, but 2-level 
factors are coded as 1 and 2 in R.
```{r, fig.keep = "last", message = FALSE}
smoker.mod <- glm(outcome ~ smoker + age, data = Whickham, family = binomial)
smoker.fun <- makeFun(smoker.mod)
smoker.fun(age = 60, smoker = "Yes")
smoker.fun(age = 60, smoker = "No")
xyplot(outcome ~ age, groups = smoker, data = Whickham, jitter.y = TRUE)
plotFun(1 + smoker.fun(age, smoker = "No") ~ age, col = 1, add = TRUE)
plotFun(1 + smoker.fun(age, smoker = "Yes") ~ age, col = 2, add = TRUE)
```

This wrapper around `predict()` is easier for beginners to use because 
(a) it returns a function to which inputs can be supplied without creating a data frame, 
(b) the resulting function returns values on the response scale by default, and (c) it 
back transforms a few common transformations of the response variable, 
including `log()` and `sqrt()` (and allows the user to provide a custom value to
the `transform` argument to handle other cases).
```{r, message = FALSE, fig.keep = "last"}
mtcars.mod <- lm(log(mpg) ~ log(wt) + factor(cyl), data = mtcars)
mileage <- makeFun(mtcars.mod)
xyplot(mpg ~ wt, data = mtcars, groups = cyl)
plotFun(mileage(w, cyl = 4) ~ w, add = TRUE, col = 1)
plotFun(mileage(w, cyl = 6) ~ w, add = TRUE, col = 2)
plotFun(mileage(w, cyl = 8) ~ w, add = TRUE, col = 3)
```

For many simple models, creating a plot can be even simpler using
`plotModel()`, which also eliminates the need to manually adjust
logistic regression plots when the response is a factor.  For models with 
multiple predictors, we can supply a formala to indicate which predictor
we prefer to have on the x-axis.
```{r}
plotModel(cars.mod2)
plotModel(smoker.mod, outcome ~ age, jitter.y = TRUE)
```

\noindent
The `plotModel()` function can also simplify visualization of more complex models.
```{r}
mtcars.mod2 <- lm(mpg ~ log(wt) + factor(cyl) + factor(am), data = mtcars)
plotModel(mtcars.mod2, mpg ~ wt | factor(am))
```


## The extractor template

The use of `makeFun()` to create a function from a model illustrates another important template: the
extractor template:

```{r, eval = FALSE}
object <- { some computation }
extractor(object)
```

R has many such extractors which summarise, display, or extract partial information from an 
object. `print()`, `plot()`, and `summary()` are examples of extractors that can be applied to many
types of objects.  Other extractors, like `resid()` and `fitted()` are designed to work with
a much smaller set of objects.  The \pkg{mosaic} package defines several extractors including
\begin{center}
\begin{tabular}{ll}
\hline
extractor   & purpose
\\
\hline
\code{makeFun()} & extract a fitted function from a model \\
\code{rsquared()}& extract $r^2$ from a linear model \\
\code{stat()}    & extract the test statistic from a hypothesis test \\
\code{pval()}    & extract the p-value from a hypothesis test \\
\code{interval()}& extract the confidence interval from a hypothesis test \\
\code{mplot()}   & create a plot from an object \\
\hline
\end{tabular}
\end{center}

```{r, extractors}
interval(t.test( ~ age, data = Whickham))      # works for any "htest" object
pval(t.test(age ~ smoker, data = Whickham))    # works for any "htest" object
stat(t.test(age ~ smoker, data = Whickham))    # works for any "htest" object
rsquared(lm(age ~ smoker, data = Whickham))
```


## mplot()

The `mplot()` function has two primary use cases: 
creating diagnostic plots for lm and glm objects, and
interactively creating data visualizations using the variables in a data frame.
Given a model object as its first argument, `mplot()` provides similar diagnostic plots to those
produced via `plot()` but with two primary differences: the user may select to use either 
\pkg{lattice} or \CRANpkg{ggplot2} \citep{ggplot2} graphics instead of base graphics, 
and an additional plot type is provided to visualize the 
confidence intervals for the coefficients of the model.

```{r, results = "hide"}
mod <- lm(length ~ width * sex, data = KidsFeet)
mplot(mod, system = "lattice", which = 1:4)
```
```{r, results = "hide"}
mplot(mod, system = "ggplot2", which = 4:7)
```

We can also use `mplot()` to visually represent the results of `TukeyHSD()`,
which has been modified so that it can be applied directly to objects produced by `lm()`.
```{r, fig.height = 5}
mplot(TukeyHSD(lm(births ~ wday, data = Births78)), order = "pval")
```
\noindent
Again, there are options to create either \pkg{lattice} or \pkg{ggplot2} plots, and 
the resulting plots are formatted in a way that makes them usable in a wider range of 
scenarios than are those produced using `plot()`.

A second use for `mplot()` is to create \pkg{lattice} and \pkg{ggplot2} plots
interactively within RStudio.  Issuing the following command in RStudio
will bring up a plot that can be modified by making choices interactively.

```{r eval = FALSE}
mplot(HELPrct)
```

\begin{figure}
\includegraphics{half-mplot.png}
\caption{In RStudio, \texttt{mplot()} can be used to interactively generate 
plots using variables in a data frame.}
\label{fig:mplot}
\end{figure}

\noindent
The menu (see Figure \ref{fig:mplot}) allows the user to choose either \pkg{lattice} or \pkg{ggplot2}
graphics, to select the type of plot and the variables used, and to control
a few of the most commonly used features that modify a plot (faceting, color, legends,
log-scaling, fitting a linear model or LOESS smoother).  The "Show Expression" button
exports the command used to create the plot into the console.  From there it can be edited
or copied and pasted into an R Markdown document.
This can be very useful for new users working to master the syntax for a particular
graphical display.


# Randomization and Resampling

Resampling approaches have become increasingly important in statistical education 
\citep{Tintle:TAS:2015, Hesterberg:2015}.
The \pkg{mosaic} package  provides simplified functionality to support teaching inference
based on randomization tests and bootstrap methods.  Our goal was to focus attention
on the important parts of these techniques (e.g., where randomness enters in and how to
use the resulting distribution) while hiding some of the technical details
involved in creating loops and accumulating values.

## A first example

As a first example, we often introduce the story of the lady tasting tea.  (See
\cite{Salsburg:2002} for the details of this famous story.)  But here we will
test a coin to see whether it is a "fair coin".  Suppose we flip the coin 20 times
and observe only 6 heads, how suspicious should we be that the coin is not fair?
The statistical punchline for either the lady tasting tea or testing a coin 
is that we want to compute the p-value for a binomial 
test via simulations rather than using formulas for the binomial distribution or 
normal approximations. But we want to do this on the first day of class, and without
using any of the jargon of the preceding sentence.

Because students do not know about sampling distributions or random variables yet, 
but do understand the idea of a coin toss, 
we have provided `rflip()` to simulate tossing a coin one or several times:
```{r}
rflip()
rflip(20)
```
To test a null hypothesis of a fair coin, we need to simulate flipping 20 coins many times,
recording for each simulation the number of heads that were observed.
The `do()` function allows us to do just that using the following template

```{r eval = FALSE}
do(n) * {stuff to do}             # pseudo-code
```
\noindent
where `{stuff to do}` is typically a single R command, but may be something more complicated.  We teach this syntax
by reading it aloud:  "Do n times ..."
For example, we can flip 20 coins three times as follows.
```{r}
do(3) * rflip(20)   # do 3 times flip 20 coins
```
\noindent
Notice that `do()` (technically `cull_for_do()`) has been clever about what information 
is stored for each group of 20 coin tosses and that the results are returned in a data 
frame.  


It is now a simple matter to do this many more
times and use numerical or graphical summaries to investigate how unusual it is to get
so few heads if the coin is indeed a fair coin.
```{r}
Sims <- do (1000) * rflip(20)
histogram( ~ heads, data = Sims, width = 1, groups = heads <= 6)
tally ( ~ (heads <= 6), data = Sims)
```
\noindent
Readers familiar with \pkg{lattice}, you will notice that the \pkg{mosaic} package
also adds some additional arguments to the `histogram()` function.  Among these are 
\code{width} and \code{center} which can be used to control the width and position
of the bins and are much easier for new users to master than the \code{breaks} argument
supplied by \pkg{lattice}.


## sample(), resample(), and shuffle()

To facilitate randomization and bootstrapping, \pkg{mosaic} extends `sample()` to operate
on data frames.  The `shuffle()` function is  an alternative name for `sample()`, and `resample()` 
is `sample()` with `replace = TRUE`.  With these in hand, all of the tests and confidence
intervals seen in a traditional first course in statistics can be performed using a common
outline:

  1. Do it to your data
  2. Do it to a randomized version of your data
  3. Do it to lots of randomized versions of your data.
 
For example, we can use randomization in place of the two-sample t test to
obtain an empirical p-value.
```{r, include = FALSE}
set.seed(12432)
```

```{r, do-diff-mean, digits = 3}
D <- diffmean(age ~ smoker, data = Whickham); D 
do(1) * diffmean(age ~ shuffle(smoker), data = Whickham)
Null.dist <- do(5000) * diffmean(age ~ shuffle(smoker), data = Whickham)
histogram( ~ diffmean, data = Null.dist, v = D)
prop( ~ (diffmean < D), data = Null.dist, format = "prop")
```
\noindent
None of the 5000 replications led to a difference in means as large as the one in the original data.

It should be noted that although this is typically not done in simulation-based introductory 
statistics texts, one might prefer to calculate p-values by including the 
observed data in the randomization distribution.  This avoids an empirical p-value of 0
and guarantees that the actual type I error rate will not exceed the nominal type I error rate.
This amounts
to adding one to the numerator and denominator.  The `prop1()` function automates this for us


```{r}
prop1( ~ (diffmean < D), data = Null.dist, format = "prop")
1/5001
```
\noindent
For more precise estimation of small p-values, additional replications should be used.


The example above introduces three additional \pkg{mosaic} functions.
The `prop()` and `prop1()` functions compute the proportion of logical vector that is (by default) `TRUE` 
or of a factor that is (by default) in the first level;
`diffmean()` is similar to `diff(mean())`, but labels the result differently
(`diffprop()` works similarly for differences in proportions). 


If we are interested in a confidence interval for the difference in group means, we can use
`resample()` and `do()` to generate a bootstrap distribution in one of two ways.
```{r}
Boot.dist1 <- do(1000) * diffmean(age ~ smoker, data = resample(Whickham))
Boot.dist2 <- do(1000) * diffmean(age ~ smoker, data = resample(Whickham, groups = smoker))
```
\noindent
In the second example, the resampling happens within the sex groups so that the marginal
counts for each sex remain fixed.  This can be especially important if one of the groups
is small, because otherwise some resamples might not include any observations of that
group.

```{r, include = FALSE}
set.seed(123456)
```
```{r}
favstats(age ~ smoker, data = Whickham)
favstats(age ~ smoker, data = resample(Whickham))
favstats(age ~ smoker, data = resample(Whickham, groups = smoker))  # fix margins
```

Using either bootstrap distribution, two simple confidence intervals can be 
computed.
We typically introduce percentile confidence intervals first.
A percentile confidence interval is calculated
by determining the range of a central portion of the bootstrap distribution, which can
be automated using `cdata()`.
Visually inspecting the bootstrap distribution for skew and bias is an important
step to make sure the percentile interval is not being applied in a situation where 
it may perform poorly.
```{r}
histogram( ~ diffmean, data = Boot.dist2, v = D)
qqmath( ~ diffmean, data = Boot.dist2)
cdata( ~ diffmean, p = 0.95, data = Boot.dist2)
```
\noindent
Alternatively, we can compute a confidence interval based on a bootstrap 
estimate of the standard error.
```{r}
SE <- sd( ~ diffmean, data = Boot.dist2); SE
D + c(-1,1) * 2 * SE
```
\noindent
The primary pedagogical value of the bootstrap standard error approach is its close
connection to the standard formula-based confidence interval methods.
How to replace the constant 2 with an appropriate value to create more accurate intervals
or to allow for different confidence levels is a matter of some subtlety
\citep{Hesterberg:2015}.  The simplest method is to use quantiles 
of a normal distribution, but this will undercover. Replacing the normal distribution
with an appropriate t-distribution will widen intervals and can improve coverage, but 
the t-distribution is only correct in a few cases -- such as when estimating the mean
of a normal population -- and can perform badly when the population is skewed.


Calculating simple confidence intervals can be further automated using an extension to `confint()`.
```{r}
confint(Boot.dist2, method = c("percentile", "stderr"))
```

## Additional examples

One of the package vignettes \citep{mosaic-resources:2016} contains a list of 
\pkg{mosaic}-related resources.  Included in the list are links to companion volumes 
for several textbooks, including two simulation-based texts, 
\citep{Lock5,Tintle:2016}.
Each of these companion volumes demonstrates how to use R and the \pkg{mosaic} package 
to recreate the analyses for all of the examples in the text.

## do() vs. replicate()

The usual alternative to `do()` is `replicate()`.  For simple situations,
`replicate()` can also be easy to use. Each of these stores its results
in a vector rather than in a data frame, but it otherwise very similar 
to the corresponding results above, although the first stores less information.

```{r}
replicate(3, rflip(20)) 
replicate(3, diffmean(age ~ smoker, data = resample(Whickham)))
```

Where `do()` really shines in simulations based on models.
The results returned by `do()` are stored in a tidy data frame and include
the components of the model most likely to be of interest.  

```{r}
do(3) * lm(shuffle(height) ~ sex + mother, data = Galton)
```
\noindent
Resampling from a linear model performs residual resampling:
```{r}
Galton.mod <- lm(height ~ sex + mother, data = Galton)
do(3) * lm(height ~ sex + mother, data = resample(Galton.mod))
```


\noindent
In contrast, `replicate()`
returns an object that is inscrutible and unusable for most beginners.

```{r}
replicate(3, lm(shuffle(height) ~ sex + mother, data = Galton))
```

# Some additional features of the mosaic package

## Handling missing data

When there are missing values, 
the numerical summary functions in \pkg{base} and \pkg{stats} return
results that may surprise and mystify new users.
```{r}
mean( ~ dayslink, data = HELPmiss)
```

\noindent
While there are workarounds using options to functions to drop values that are missing before performing the computation, these may be intimidating to new users.
```{r}
mean( ~ dayslink, data = HELPmiss, na.rm = TRUE)
```
We offer two other solutions to this situation.  Our favorite is the `favstats()` function
which computes a set of useful numerical summaries on the non-missing values
and also reports the number of missing values.
```{r}
favstats( ~ dayslink, data = HELPmiss)
```

The second solution is to change the default behavior of `na.rm` using `options()`.
This will, of course, only affect the \pkg{mosaic} versions of these functions.
```{r}
options(na.rm = TRUE)
mean( ~ dayslink, data = HELPmiss)
with(HELPmiss, base::mean(dayslink))
```

\noindent
Users also have the option of changing the default for `na.rm` back if they like.
```{r}
options(na.rm = NULL)
mean( ~ dayslink, data = HELPmiss)
```

## Inspecting a data frame

Summaries of all variables in a data frame can be obtained using `inspect()`.  For quantitative 
variables, the results of `favstats()` are displayed.  Other summaries are provided for 
categorical and time variables.

```{r}
inspect(Births78)
```



## Additional high-level lattice plots

The \pkg{mosaic} package provides several new high-level \pkg{lattice} plots, including
`bargraph()`, 
`dotPlot()`, 
`freqpolygon()`,
`ashplot()`,
`xqqmath()`,
and `plotPoints()`.

```{r}
bargraph( ~ smoker, data = Whickham, main = "bargraph()")
dotPlot( ~ age, data = Whickham, width = 1, main = "dotPlot()")
```
```{r}
freqpolygon( ~ age, data = Whickham, width = 5, main = "freqpolygon()")
ashplot( ~ age, data = Whickham, width = 5, main = "ashplot()")
```
```{r}
xqqmath( ~ age, data = Whickham, main = "xqqmath()")
plotPoints(length ~ width, data = KidsFeet, main = "plotPoints()")
```

The `bargraph()` function eliminates the need to first summarize the data before constructing a plot with
`barplot()` and makes creating these plots from raw data simpler.
The dot plots produced by `dotPlot()` are 
quite different from the Cleveland-style dot plots produced by `dotplot()`.  The former are essentially
histograms made of stacked dots and can be seen in many 
introductory statistics texts.  They are also useful for producing plots from which students can quickly estimate
p-values by counting dots in the tail of a randomization distribution.
Frequency polygons and ASH plots (average shifted histograms) are less common, but share many features in common
with density plots and are easier to explain to students.
The main motivation for `plotPoints()` is the abbility to use it to create additional layers on an existing plot
with the option `add = TRUE`, otherwise `xyplot()` would suffice.  

## Basic choropleth maps

We provide functionality for creating basic choropleth maps: `mUSMap()` and `mWorldMap()` provide simple 
ways to construct choropleth maps of states in the US or countries in the world, and `makeMap()` allows users
to provide their own map data.

```{r, message = FALSE}
USArrests <- USArrests %>% mutate(state = row.names(USArrests))
mUSMap(USArrests, key = "state", fill = "UrbanPop")
```

## Work-arounds for unfortunate name collisions

The \pkg{mosaic} package depends on \pkg{lattice} and \pkg{ggplot2} so that plots 
can be made using either system whenever the \pkg{mosaic} package is attached.  It also 
depends on \CRANpkg{dplyr} \citep{dplyr}, but for a different reason.  The functions in \pkg{dplyr} 
implement a "less volume, more creativity" approach to data transformation and we 
encourage its use along side \pkg{mosaic}.  Unfortunatley, there are several
function names -- most notably `do()` and `tally()` -- that exist in both packages.
After the release of \pkg{dplyr} we modified the functions in \pkg{mosaic} so
that the two packages can coexist amicably as long as \pkg{mosaic} comes before 
\pkg{dplyr} in the search path.

## But wait, there's more

Table \ref{tbl:otherstuff} lists some additional functions in the \pkg{mosaic} package 
not highlighted above.  
The package also contains three templates for creating 
R Markdown documents in RStudio.  Each ensures that the \pkg{mosaic} package 
is attached, sets the default theme for \pkg{lattice} graphics to 
`theme.mosaic()`, chooses a somewhat smaller default size for graphics, and includes
a comment reminding users to attach any packages they intend to use.
The "fancy" template demonstrates several features of R Markdown, and the "plain" 
templates allow users to start with a clean slate.
See \cite{Baumer:RMarkdown:2014} for a discussion of how R Markdown can be used 
in statistics courses.

\begin{table}
\begin{tabular}{lp{4in}}
\toprule
function & uses
\\
\midrule
\texttt{CIsim()} & demonstrate coverage rates of confidence intervals.
\\
\texttt{statTally()} & investigate test statistics and their empirical distributions.
\\
\texttt{panel.lmbands()} & add confidence and prediction bands to scatter plots.
\\
\texttt{ladd()} & simplified layering in \pkg{lattice} plots.
\\
\texttt{xchisq.test()} & an extension to \texttt{chisq.test()} that prints a table including
observed and expected counts, contribution to the chi-squared statistics and residuals.
\\
\texttt{zscore()} & convert a numeric vector into z-scores.
\\
\texttt{D()}, \texttt{antiD()} & derivative and antiderivative operators that take a function
as input and return a function.   For simple functions, the operations are done symbolically.
\\
\texttt{col.mosaic()} & a \pkg{lattice} theme with colors that project better than the 
\pkg{lattice} defaults.
\\
\texttt{dot()}, \texttt{project()}, \texttt{vlength()} & linear algebra on vectors.
\\
\texttt{ediff()} & like \texttt{diff()}, but the returned vector is padded with \texttt{NA}s
so that the length is the same as the input vector.
\\
\texttt{SAD()}, \texttt{MAD()} & all pairs sum and mean of absolute differences
\\
\texttt{rgeo()} & randomly sample latitidue, longitude pairs uniformly over the globe
\\
\texttt{googleMap()} & show google maps in a browser.  Together with \texttt{rgeo()}, this can be 
used to view maps of randomly selected points on the globe.  See \cite{RoadlessAmerica}
for an example of how this can be used for a classroom activity.
\\
\bottomrule
\end{tabular}
\caption{Some additional functions in the \pkg{mosaic} package.}
\label{tbl:otherstuff}
\end{table}


# Discussion

## Advantages of the mosaic approach

One of the keys to successfully empowering students to think with data is providing them 
both a conceptual framework that allows them to know what to look for and how to interpret
what they find, and a computational toolbox that allows them to do the looking.
The approach made possible with the \pkg{mosaic} package simplifies 
the transition from thinking to computing by reducing the number of computational templates
students learn so that cognitive effort can be spent elsewhere, and 
by having those templates reflect, support, and deepen the underlying thinking 
\citep{Grolemund:ISR:2014}.

Because of the connection between conceptual understanding and these computational tools,
the use of R can also help reveal misunderstandings that might otherwise go unnoticed.
For example, if a student attempts to use `t.test()` or to create a histogram using a categorical
variable, the student will receive error or warning messages that are an indication that either
the student does not understand the current data set or still has confusion regarding what it means
for a variable to be categorical or continuous and which operations are suited for each kind of variable.
We encourage students to make sure they can answer two important questions before attempting 
to issue a command in R:

  1. What do I want the computer to do for me?
  
  2. What does it need to know in order to do that?
  
If these two questions can be answered clearly and correctly, then the student's primary issue is one of 
creating the correct R code.  If they cannot, then the problem lies elsewhere. In our experience, students
who can consistently answer these two questions have relatively little trouble translating the answers into
R code using the commands we teach.

For students who take additional courses after the first course, R has the capability to
support the increasing complexity of the data and analyses students encounter in subsequent
courses and research projects.  Eventually, students will need to learn more about the 
structure of R as a language, the types of objects it supports, and alternative ways of
approaching the same task.  But early on, it is more important that students can successfully
and independently exercise computational and statistical creativity.

## Challenges of using R in introductory courses

But using R is not without some challenges.  The first challenge is to get all 
of the students
up and running with R.  The use of an RStudio server allows an institution
or instructor to install and configure R and its packages and students to work 
within a web 
browser, essentially eliminating the start-up costs for the students.  
Otherwise, instructors
must assist students as they navigate installation of R and whichever additional packages
are required. 

Once students have access to R, the \pkg{mosaic} package reduces, but does not eliminate,
the amount of syntax students need to learn.  It is important to emphasize the similarity 
among commands within a template, to remind students that R is case sensitive, to show them
how to take advantage of short cuts
like tab completion and code history navigation, and to explicitly teach students
how to interpret some of the most common R error messages.  This goes a long way toward smoothing
the transition to a command line interface that is not as forgiving as Google search, which 
may be many students' only other experience with a command line interface.

In our experience, the most commonly occuring struggles for students using \pkg{mosaic}
are

 1. General anxiety over typing commands.
 
    Although students are very familiar with using computers and computerized
    devices like smart phones,
    many of them have little experience typing commands that require following syntax rules.  The 
    "Less Volume, More Creativity" approach helps with this, by reducing the volume, but it remains
    important to highlight repeatedly the similarities among commands and to help students learn to 
    understand the most common error messages R produces so that they can quickly, easily, 
    and comfortably recover from innevitable typing errors.  
    Even if a class does not typically meet in a computer laboratory
    or take advantage of studetn laptops, it can be useful to arrange some sessions early in 
    the course where students are using RStudio while someone is there to quickly help them when 
    they get stuck.  Avoiding frustration in students' early experience with R goes a long way in
    overcoming anxiety.
 
    As a bonus instructional method, the authors make frequent
    typing mistakes in front of the class.  While we could not avoid this if we tried, 
    it does serve to demonstrate both how to recover from errors and that nothing drastic 
    has happened when an error message is displayed.
 
    One big advantage of the command line interface is that it is much easier to help students 
    by email or in a discussion forum.  Encourage students to copy both their commands and 
    the error messages or  output that were produced.  
    Even better, have them share their work in the form of an R Markdown file.
    We find students are much more capable of doing this than they are of 
    correctly describing the chain of events they initiated in a menu-driven system.  
    (It is also much easier to give detailed instructions and examples.)
 
 2. Confusion over the tilde (`~`).
 
    The tilde is a small symbol, easily overlooked on the screen or on paper (or mistaken for `-`), 
    so students will sometimes omit it, or put it where it doesn't belong.  For several of our functions, 
    we allow `x` in place of
    `~ x` to help ease the pain of mistyping things.  But we recommend that
    instructors teach the use of `~` in all situations.  A similar thing occurs
    with explicitly naming the `data` argument, which is not required for the \pkg{lattice} functions, 
    but is for several other functions.  Teaching the forms that work in all contexts is easier
    than teaching which contexts allow which forms.
 
    As a visual aid, we recommend surrounding the `~` with a space on either side, even in 1-sided
    formulas.
 
 3. Difficulty in setting up the R environment
 
    This is all but eliminated when using and RStudio server, but in situations where instructors prefer
    a local R installation for each student, there are often a few issues involved in getting all students
    up and running.  Installation of R and RStudio is straightforward, but one should make sure that students
    all have the latest version of each.  To use the \pkg{mosaic} package, a number of additional packages
    must be installed.  We recommend beginning with 
```{r, eval = FALSE}
update.packages()
```
or the equivalent operation from the RStudio Packages tab to make sure all packages currently on the system
are up to date.  In most cases,
```{r, eval = FALSE}
install.packages("mosaic")
```
(again, this can also be done via the Packages tab in RStudio) will take care of the rest.  But ocassionally
some package will not install correctly on a particular student's computer. Installing that package
directly rather than as part of the dependencies of \pkg{mosaic} often solves this problem or at 
least provides a useful diagnostic regarding what the problem might be.


## Efficiency Issues

For applications where speed is of utmost 
importance, the \pkg{mosaic} wrappers may not be the optimal approach. 
For the numerical summary functions, the \pkg{mosaic} versions cannot be
faster than their counterparts in \pkg{base} or \pkg{stats} (because 
eventually they call the underlying functions) and may be noticeable slower in contexts where
they are called many times.
In particular, using the formula interface requires parsing the formula and 
creating a new object to contain the data described by the formula.
On the other hand, for aggregated numerical summaries, the loss in performance may represent
a small price to pay for the simplified syntax.

Similarly, using `do()` comes at a price, although here the the increased computation
time has more to do with 
the extra work involved in culling the objects and reformatting the results.  The looping
itself is as fast as using `replicate()` -- indeed the underlying code is very similar -- and 
can be faster when the \CRANpkg{parallel} package is attached; 
even on a laptop with a single quad-core processor, the speed-up is noticible.

## Be selective

Over the years we have been developing the \pkg{mosaic} package, it has grown to the point that it now contains much
more than a minimally sufficient set of commands for an introductory course.  While we have attempted to give 
some sense of the scope of the package in this article, we advise instructors to use things selectively, keeping in
mind their students and the goals for the course.  What may represent just the right tool in one setting may be 
too much in another.  Of course, the same advice holds for using functions from other packages as well.
The instructor's temptation is always to do too much, forgetting the cognitive burden this can place on students.
Less volume and more creativity will at times pull in opposite directions, and a skilled instructor must determine
the appropriate balance for each setting.

# Acknowledgements

Partial support for this work was provided by the National Science Foundation 
DUE 0920350 (Project MOSAIC).  We thank Xiaofei (Susan) Wang and the reviewers for helpful comments 
and suggestions, and all of the users of the \pkg{mosaic} package who have provided use feedback
on their experience and offered suggestions for improvement.

\bibliography{pruim-horton-kaplan}
