---
title: The mosaic package&#58; helping students to 'think with data' using R
author:
  - name: Randall Pruim
    affiliation: Calvin College
    address:
    - 3201 Burton St SE
    - Grand Rapids, MI 49546
    email:  rpruim@calvin.edu
  - name: Daniel T Kaplan
    affiliation: Macalester College
    address:
    - address 1
    - address 2
    email:  dtkaplan@macalester.edu
  - name: Nicholas J Horton
    affiliation: Amherst College
    address:
    - Department of Mathematics and Statistics
    - PO Box 5000  AC \#2239
    - Amherst, MA 01002-5000
    email:  nhorton@amherst.edu
abstract: >
  The mosaic package provides a simplified and systematic introduction to the core functionality related to descriptive statistics, visualization,  modeling, and simulation-based inference required in first and second courses in  statistics. This introduction to the package describes some of the guiding principles  behind the design of the package and provides illustrative examples of several of the most  important functions it implements.  These can be combined to help students  ``think with data" using R in their early course work,  starting with simple, yet powerful, declarative commands.


preamble: >
  % Any extra latex you need in the preamble
output: rticles::rjournal_article
---

```{r, include=FALSE}
require(mosaic)
knitr::opts_chunk$set(
  fig.width = 4.5, fig.height = 3, 
  out.width = ".45\\textwidth",
  fig.show="hold", fig.align = "center",
  cache=TRUE
)
options(digits = 3)
trellis.par.set(theme = col.mosaic())
# trellis.par.set(fontsize = list(text=8, points = 5))
set.seed(123)
mytheme <- theme_minimal() 
```

# Motivation

Many have argued that 
in order to make sense of the increasingly rich data that is
available to them 
students need additional facility to express statistical computations (e.g., 
\cite{NolanTempleLang:2010, Ridgway:2015, HortonBaumerWickham:2015}).
To be able to "think with data" (as coined by Diane Lambert of Google), students
need to access tools for data management, exploratory analysis,
visualization, and modeling.  Yet many students enter statistics courses
with little or no computational experience.
We have demonstrated that it is feasible to
integrate computing into our curricula early and often,
in a way that provides students with success, confidence, and room to grow.


# A guiding principle: Less volume, more creativity

The \CRANpkg{mosaic} package originated in early attempts by each of the authors to 
ease new users into using R, primarily in the context of 
undergraduate statistics courses, and, in one case, also in calculus.
One of the guiding principles behind the development of the \CRANpkg{mosaic} package
has been "Less volume, more creativity".  Beginners are easily overwhelmed by the 
scope of R and its many packages.  Often there are multiple ways to accomplish the 
same task, and authors of the many packages are not required to follow any particular
style guidelines.

Early on in the development of \CRANpkg{mosaic}, we decided to
reduce the number of code templates that users would need to know to as few as possible,
while still providing them with substantial power to be creative within the
templates provided.
A one-page list of commands that are more than sufficient for a first course, originally
presented as part of a roundtable discussion at the Joint Statistics Meetings in 2011 now
appears as a vignette in the package, along with some additional material on the 
less volume, more creativity approach.

# The formula template

To successfully implement a "less volume, more creativity" approach, one must decide
which tasks are most important to accomplish.  We knew from the outset that
this would include graphical and numerical summaries of data and various models
and inference procedures.  Because of this goal, 
our most important template makes use of a "formula interface"
modeled after \code{lm()} and the plotting functions in \CRANpkg{lattice}. 

We typically introduce the formula template in the context of exploring 
two variables as 

```{r, eval=FALSE}
goal( y ~ x, data = mydata )
```
\noindent
For a plot, `goal` names the type of plot, `y` and `x` name the variables to be 
mapped to the vertical and horizontal axes, and `mydata` is the data frame in which 
these variables are found.
This template allows us to create, for example, scatterplots and side-by-side box plots
using \CRANpkg{lattice} functions.  Here we illustrate using the `Births78`
data set from the `mosaicData` package, which, as the name suggests, contains data sets
to accompany the `mosaic` package.
```{r}
xyplot(births ~ date, data = Births78)
```
```{r}
bwplot(births ~ wday, data = Births78) 
bwplot(wday ~ births, data = Births78, pch = "|")
```
\noindent
With the \CRANpkg{mosaic} package attached, the same template can be used to create 
numerical summaries.
```{r}
mean(births ~ wday, data = Births78)
sd(births ~ wday, data = Births78)
favstats(births ~ wday, data = Births78)
```
\noindent
We introduced a `tally()` function for counting categorical variables.  Notice that in 
final example, conditional proportions are calculated.
```{r}
tally(sex ~ substance, data = HELPrct)
tally(sex ~ substance, data = HELPrct, margins = TRUE)
tally(sex ~ substance, data = HELPrct, margins = TRUE, format = "proportion")
```

Formula interfaces are provided for 
`mean()`, `median()`, 
`sd()`, `var()`, `cor()`, `cov()`,
`quantile()`, 
`max()`, `min()`, `range()`, 
`IQR()`, `iqr()`, `fivenum()`,
`prod()`, and `sum()`.
In each case we have been careful not to break behavior of the underlying functions from
\CRANpkg{base} and \CRANpkg{stats}.

The formula template can be extended to handle one variable or more than two variables,
but we recommend introducing it in the context of two-variable plots and summaries.
This is for several reasons: (1) two-variable plots and numerical summaries are more
"impressive" and less likely to be something students can as readily do with tools they 
already know, (2) working with more than one variable from the start (correctly) suggests
that the most interesting parts of statistics involve more than one variable \cite{Wild:RSS:2011}
and 
(3) the formula syntax for a single variable makes more sense in the context of two-sided
formulas that it does in isolation.

Once the two-variable summaries are understood, we can add a third and fourth variable with
```{r, eval=FALSE}
goal( y ~ x | z, groups = mygroups, data=mydata )
```
\noindent
When plotting, `z` is used to create plots with subpanels (or facets) and `groups` is
used to overlay multiple layers.
```{r}
xyplot(births ~ date, groups = wday, data = Births78, type = "l")
densityplot( ~ births, groups = wday, data = Births78, auto.key=list(columns=3))
densityplot( ~ age | sex, groups = substance, data = HELPrct)
```

For numerical summaries, these play the same role which allows us to compute 
numerical summaries by changing the name of the plot into the name of the desired
summary.
```{r}
mean( ~ age | sex, groups = substance, data = HELPrct)
```

The one-variable template can be obtained by removing the left-hand side from the formula
in a two-variable template.
```{r, eval=FALSE}
goal( ~ x, data=mydata )
```
\noindent
In the context of plotting, this makes sense since we are providing the data for the 
$x$-axis and allowing R to compute values for the $y$-axis:
```{r}
histogram( ~ age, data = HELPrct)
```
\noindent
Numerical summaries fit this pattern by analogy (and because R formulas are required to
have a right hand side).
```{r}
mean( ~ age, data = HELPrct)
```

As students become familiar with the formula interface,
all three forms can be brought together into a single template:

```{r, eval=FALSE}
goal( formula, data=mydata, ... )
```
\noindent
The formula template allows us to very quickly introduce students to 
thinking about relationships between and among two or more variables and
allows them to test conjectures using graphical and numerical summaries.
Having learned the formula interface to graphical and numerical
summaries early on, new users are well prepared for modeling with
\code{lm()}, \code{glm()}, and various "test" functions such as
`t.test()` when the time comes and they begin early to train their minds
to ask questions of the form "How does this depend on that (and some other things)?". 

By emphasizing the formula template, each of the following commands can be 
viewed as instances of a common template, rather than as separate things 
to learn. 


```{r, tidy=FALSE, eval=FALSE}
bwplot(age ~ sex, data=HELPrct)
  mean(age ~ sex, data=HELPrct)
    sd(age ~ sex, data=HELPrct)
    lm(age ~ sex, data=HELPrct)
t.test(age ~ sex, data=HELPrct) 
```

\noindent
Similarly, by adding additional formula interfaces to `t.test()`,
`binom.test()`, and `prop.test()`, and adding some additional 
plot types, for one-variable situations we have 

```{r, tidy=FALSE, eval=FALSE}
       mean( ~ age, data=HELPrct)
         sd( ~ age, data=HELPrct)
   favstats( ~ age, data=HELPrct)
  histogram( ~ age, data=HELPrct)
    dotPlot( ~ age, data=HELPrct)   # dot plots
freqpolygon( ~ age, data=HELPrct)   # frequency polygon
    ashplot( ~ age, data=HELPrct)   # average shifted histogram
     t.test( ~ age, data=HELPrct)   # formula interface added in mosaic
 binom.test( ~ sex, data=HELPrct)   # formula interface added in mosaic
  prop.test( ~ sex, data=HELPrct)   # formula interface added in mosaic
```

\noindent
Adding covariates to one- or two- variable graphical or numerical summaries
fits readily into the template as well.
```{r, tidy=FALSE, eval=FALSE}
     mean( ~ age | sex, data=HELPrct)
       sd( ~ age | sex, data=HELPrct)
histogram( ~ age | sex, data=HELPrct)
   t.test( ~ age | sex, data=HELPrct)
```

While creating the correct formula can produce some initial challenges for users, 
clearly explaining the roles of each component for plotting, 
for numerical summaries, and for model fitting helps demystify the situation. 
We have also found that explicit, early, low-stakes assessment of student mastery
of the formula interface greatly improves student performance (XX see sample quiz and study guide at XX).


## Handling missing data

When there are missing values, 
the numerical summary functions in \CRANpkg{base} and \CRANpkg{stats} return
results that may surprise and mystify new users.
```{r}
mean( ~ dayslink, data = HELPmiss)
```

\noindent
While there are workarounds using options to functions to drop values that are missing before performing the computation, these may be intimidating to new users.
```{r}
mean( ~ dayslink, data = HELPmiss, na.rm = TRUE)
```
We offer two other solutions to this situation.  Our favorite is the `favstats()` function
which computes a number of our favorite numerical summaries on the non-missing values
but also reports the number of missing values.
```{r}
favstats( ~ dayslink, data = HELPmiss)
```

The second solution is to change the default behavior of `na.rm` using `options()`.  
This will, of course, only affect the \CRANpkg{mosaic} versions of these functions.
```{r}
options(na.rm = TRUE)
mean(~ dayslink, data = HELPmiss)
with(HELPmiss, base::mean(dayslink))
```

\noindent
Users also have the option of changing the default for `na.rm` back if they like.
```{r}
options(na.rm = NULL)
mean(~ dayslink, data = HELPmiss)
```

##  Creating and using functions

Especially in calculus, but also in statistics, it is useful to create 
functions defined by algebraic formulas.  With `makeFun()` we can construct
such functions using a formula interface, and use `plotFun()` to plot them.

```{r}
f <- makeFun(A + B * log(x) ~ x, A = 1, B = 1)
f
f(2)
plotFun(f(x) ~ x, xlim = c(0,3))
```

More interestingly for statistics, we can use `makeFun()` to create functions from
model objects created by `lm()` and `glm()`.
```{r, fig.keep = "last"}
cars.mod <- lm(dist ~ poly(speed,2), data = cars)
dist <- makeFun(cars.mod)
dist(speed = 15)
dist(speed = 15, interval = "confidence")
xyplot(dist ~ speed, data = cars)
plotFun(dist(s) ~ s, add = TRUE)
```

\noindent
For logistic regression with factors, we need to adjust things slightly when plotting
because the model functions returns values between 0 and 1, but 2-level factors are coded 
as 1 and 2.
```{r}
Feet.mod <- glm(sex ~ width, data = KidsFeet, family = binomial)
s <- makeFun(Feet.mod)
s(width = 8.5)
xyplot(sex ~ width, data = KidsFeet)
plotFun(1 + s(w) ~ w, add = TRUE)
```

This wrapper around `predict()` is easier for beginners to use because 
(a) it returns a function to which inputs can be supplied without creating a data frame, 
(b) the resulting function returns values on the response scale by default, and (c) it 
back transforms a few common transformations of the response variable, 
including `log()` and `sqrt()` (and allows the user to provide a custom value to
the `transform` argument to handle other cases).
```{r, message = FALSE, fig.keep = "last"}
mtcars.mod <- lm(log(mpg) ~ log(wt) + factor(cyl), data = mtcars)
mileage <- makeFun(mtcars.mod)
xyplot(mpg ~ wt, data = mtcars, groups = cyl)
plotFun( mileage(w, cyl=4) ~ w, add = TRUE, col = 1)
plotFun( mileage(w, cyl=6) ~ w, add = TRUE, col = 2)
plotFun( mileage(w, cyl=8) ~ w, add = TRUE, col = 3)
```

For many simple models, creating a plot can be even simpler
```{r}
plotModel(cars.mod)
```

\noindent
The `plotModel()` function can also simplify visualization of more complex models.
```{r}
mtcars.mod2 <- lm(mpg ~ log(wt) + factor(cyl) + factor(am), data = mtcars)
plotModel(mtcars.mod2, mpg ~ wt | factor(am))
```

# Randomization and Resampling

Resampling approaches have become increasingly important in statistical education (\cite{Tintle:TAS:2015})
The \CRANpkg{mosaic} package  provides simplified functionality to support teaching inference
based on randomization tests and bootstrap methods.  Our goals was to focus attention
on the important parts of these techniques (e.g., where randomness enters in and how to
use the resulting distribution) while hiding some of the technical details
involved in creating loops and accumulating values.

As a first example, we often introduce the story of the lady tasting tea.  (See
\cite{Salsburg:2002} for the details of this famous story.)  But here we will
test a coin to see whether it is a "fair coin".  Suppose we flip the coin 20 times
and observe only 6 heads, how suspicious should we be that the coin is not fair?
The statistical punchline for either the lady tasting tea or testing a coin 
is that we want to compute the p-value for a binomial 
test via simulations rather than using formulas for the binomial distribution or 
normal approximations. This allows us to introduce this example on the first day of class.

Since students generally do not know about sampling distributions yet, but do understand the idea of a coin
toss, we have provided `rflip()` to simulate tossing a coin one or several times:
```{r}
rflip()
rflip(20)
```
To test a null hypothesis of a fair coin, we need to simulate flipping 20 coins many times,
recording for each simulation the number of heads that were observed.
The `do()` function allows us to do just that using the following template

```{r eval = FALSE}
do(n) * {stuff to do}
```
\noindent
where stuff to do is typically a single R command, but may be something more complicated.
For example, we can flip 100 coins three times as follows.
```{r}
do(3) * rflip(100)
```
\noindent
Notice that `do()` (technically `cull_for_do()`) has been clever about what information 
is stored for each group of 100 coin tosses.  It is now a simple matter to do this many more
times and use numerical or graphical summaries to investigate how unusual it is to get
so few heads if the coin is indeed a fair coin.
```{r}
Sims <- do (1000) * rflip(20)
histogram( ~ heads, data = Sims, width = 1, groups = heads <= 6)
tally ( ~(heads <= 6), data = Sims)
```
\noindent
(If you are familiar with \CRANpkg{lattice}, you will notice that the \CRANpkg{mosaic} package
also adds some additional arguments to the `histogram()` function.)

## sample(), resample(), and shuffle()

To facilitate randomization and bootstrapping, \CRANpkg{mosaic} extends `sample()` to operate
on data frames.  The `shuffle()` function is  an alternative name for `sample()` while `resample()` 
is `sample()` with `replace = TRUE`.  With these in hand, all of the tests and confidence
intervals seen in traditional first course in statistics can be performed using a common
outline:

  1. Do it to your data
  2. Do it to a randomized version of your data
  3. Do it to lots of randomized versions of your data.
  
For example, we can use randomization in place of the two-sample t test to
obtain an empirical p-value.
```{r}
pval(t.test(age ~ sex, data = HELPrct, alternative = "greater"))
```

```{r}
D <- diffmean(age ~ sex, data = HELPrct); D
do(1) * diffmean(age ~ shuffle(sex), data = HELPrct)
Null.dist <- do(5000) * diffmean(age ~ shuffle(sex), data = HELPrct)
histogram(~diffmean, data = Null.dist, v = D)
prop( ~(diffmean < D), data = Null.dist, format = "prop")
```

The example above introduces three additional \CRANpkg{mosaic} functions.
`pval()` extracts the p-value from an object of class `"htest"`; 
`prop()` computes the proportion of logical vector that is (by default) `TRUE` 
or of a factor that is (by default) the first label;
and
`diffmean()` is similar to `diff(mean()`, but labels the result differently.
`diffprop()` works similarly for differences in proportions.

It should be noted that one might prefer to calculate p-values by including the 
observed data in the randomization distribution.  This avoids an emprical p-value of 0
and guarantees that the actual type I error rate will not exceed the nominal type I error rate.
```{r}
count( ~ (diffmean < D), data = Null.dist)
(1 + count( ~ (diffmean < D), data = Null.dist)) / (1 + nrow(Null.dist))  # p-value
```

If we are interested in a confidence interval for the difference in group means, we can use
`resample()` and `do()` to generate a bootstrap distribution in one of two ways.
```{r}
Boot.dist1 <- do(1000) * diffmean(age ~ sex, data = resample(HELPrct))
Boot.dist2 <- do(1000) * diffmean(age ~ sex, data = resample(HELPrct, groups = sex))
```
\noindent
In the second example, the resampling happens within the sex groups so that the marginal
counts for each sex remain fixed.  This can be especially important if one of the groups
is small, because otherwise in some resamples might not include any observations of that
group.

```{r, include=FALSE}
set.seed(123456)
```
```{r}
favstats(age ~ sex, data = HELPrct)
favstats(age ~ sex, data = resample(HELPrct))
favstats(age ~ sex, data = resample(HELPrct, groups = sex))
```

Using either bootstrap distribution, two simple confidence intervals can be 
computed.
We typically introduce percentile confidence intervals first.
A percentile confidence interval is calculated
by determining the range of a central portion of the bootstrap distribution, which can
be automated using `cdata()`.
Visually inspecting the bootstrap distribution for skew and bias is an important
step to make sure the percentile interval is not being applied in a situation where 
it may perform poorly.
```{r}
histogram( ~ diffmean, data = Boot.dist2, v = D)
qqmath( ~ diffmean, data = Boot.dist2)
cdata( ~ diffmean, p = 0.95, data = Boot.dist2)
```

Alternatively, we can compute a confidence interval based on a bootstrap 
estimate of the standard error.
```{r}
SE <- sd( ~ diffmean, data = Boot.dist2); SE
D + c(-1,1) * 2 * SE
```
\noindent
How to replace the constant 2 with an appropriate value to create more accurate intervals
or to allow for different confidence levels is a matter of some subtlety
(see \cite{Hesterberg:2015}).  The simplest method is to use quantiles 
of a normal distribution, but this will undercover.  Replacing the normal distribution
with an appropriate t-distribution will widen intervals and can improve coverage, but 
the t-distribution is only correct in a few cases -- such as when estimating the mean
of a normal population -- and can perform badly when the population is skewed.
The primary pedagogical value of the bootstrap standard error approach is its close
connection to the standard formula-based confidence interval methods.

Each of these can be further automated using an extension to `confint()`.
```{r}
confint(Boot.dist2, method = c("percentile", "stderr"))
```


# Extracting information

Modeled on functions like \code{resid()}, a number of additional functions have
been added to \CRANpkg{mosaic} to facilitate extracting information from more
complicated objects.  Some examples include

```{r, extractors}
confint(t.test(~age, data=HELPrct))     # works for any "htest" object
pval(t.test(age ~ sex, data=HELPrct))   # works for any "htest" object
stat(t.test(age ~ sex, data=HELPrct))   # works for any "htest" object
rsquared(lm(age ~ sex, data=HELPrct))
```


# Some additional visualization tools

## Additional high-level lattice plots

The \CRANpkg{mosaic} package provides several new high-level \CRANpkg{lattice} plots, including
`bargraph()`, 
`dotPlot()`, 
`freqpolygon()`,
`ashplot()`,
`xqqmath()`,
and `plotPoints()`.

```{r}
bargraph( ~ substance, data = HELPrct, main = "bargraph")
dotPlot( ~ age, data = HELPrct, width = 1, main = "dotPlot")
```
```{r}
freqpolygon( ~ age, data = HELPrct, width = 2, main = "freqpolygon")
ashplot( ~ age, data = HELPrct, width = 2, main = "ashplot")
```
```{r}
xqqmath( ~ age, data = HELPrct, main = "xqqmath")
plotPoints(length ~ width, data = KidsFeet, main = "plotPoints")
```

## Visualizing distributions of random variables

A number of functions make it simple to visualize random variables.  `plotDist()` creates
displays for any distribution for which standard d-, p-, and q- functions exist.
```{r}
plotDist("norm", mean = 100, sd = 10)
plotDist("binom", size = 100, prob = 0.3)
```
\noindent
Tail probabilities can be highlighted using the `groups` argument.
```{r}
plotDist("chisq", df = 4, groups = x > 9)
plotDist("chisq", df = 4, groups = x > 9, type = "h")
```
\noindent
Using the `kind` argument, we can obtain other types of plots, including cdfs and 
probability histograms.
```{r}
plotDist("norm", mean = 100, sd = 10, kind = "cdf")
plotDist("binom", size = 100, prob = 0.3, kind = "histogram")
```

For several distributions, we provide augmented versions of the distribution and 
quantile functions that assist students in understanding what values are returned
by functions like `pnorm()` and `qnorm()`.
```{r}
xpnorm(-2:2)
xqt(0.975, df = 20)
```

## mplot()

The `mplot()` function has two primary use cases: 
creating diagnostic plots for lm and glm objects, and
interactively creating data visualizations using the variables in a data frame.
Given an model object as its first argument, `mplot()` provides similar diagnostic plots to those
produced via `plot()` but two primary differences: the user may select to use either \CRANpkg{lattice} or \CRANpkg{ggplot2} graphics instead of base graphics, and an additional plot type is provided to visualize the 
confidence intervals for the coefficients of the model.

```{r, results = "hide"}
mod <- lm(length ~ width * sex, data = KidsFeet)
mplot(mod, system = "lattice", which = 1:4)
mplot(mod, system = "ggplot2", which = 4:7)
```

We can also use `mplot()` to visually represent the results of `TukeyHSD()`,
which we can apply directly to objects produced by `lm()`.
```{r, fig.height = 5}
mplot(TukeyHSD(lm(births ~ wday, data = Births78)), order = "pval")
mplot(TukeyHSD(lm(births ~ wday, data = Births78)), order = "pval", system = "ggplot2") 
```
\noindent
Again, there are options to create either \CRANpkg{lattice} or \CRANpkg{ggplot2} plots, and 
the resulting plots are usable in a wider range of scenarios than are those 
produced using `plot()`.

A second use for `mplot()` is to create \CRANpkg{lattice} and \CRANpkg{ggplot2} plots
interactively within RStudio.  Issuing the following command in RStudio
will bring up plot that can be modified by making choices interactively.

```{r eval = FALSE}
mplot(HELPrct)
```

\begin{figure}
\includegraphics{half-mplot.png}
\caption{In RStudio, \texttt{mplot()} can be used to interactively generate 
plots using variables in a data frame.}
\label{fig:mplot}
\end{figure}

\noindent
The menu (see Figure~\ref{fig:mplot}) allows the user to choose either \CRANpkg{lattice} or \CRANpkg{ggplot2}
graphics, to select the type of plot and the variables used, and to control
a few of the most commonly used features that modify a plot (faceting, color, legends,
log-scaling, fitting a linear model or LOESS smoother).  The "show expression" button
exports the command used to create the plot into the console.  From there it can be edited
or copied and pasted in an R Markdown document.

# Additional features

Table \ref{tbl:otherstuff} lists some additional functions in the \CRANpkg{mosaic} package 
not highlighted above.  The package also contains three templates for creating 
R Markdown documents in RStudio.  
Each ensures that the \CRANpkg{mosaic} package 
is attached, sets the default theme for \CRANpkg{lattice} graphics to 
`theme.mosaic()`, chooses a somewhat smaller default size for graphics, and includes
a comment reminding users to attach any packages they intend to use.
The "fancy" template demonstrates several features of R Markdown, and the "plain" 
templates allow users to start with a clean slate.
See \cite{Baumer:RMarkdown:2014} for a discussion of how R Markdown can be used 
in statistics courses.

\begin{table}
\begin{tabular}{lp{4in}}
\hline
function & uses
\\
\hline
\texttt{CIsim()} & demonstrate coverage rates of confidence intervals.
\\
\texttt{statTally()} & investigate test statistics and their empirical distributions.
\\
\texttt{panel.lmbands()} & add confidence and prediction bands to scatter plots.
\\
\texttt{ladd()} & simplified layering in \CRANpkg{lattice} plots.
\\
\texttt{xchisq.test()} & an extension to \texttt{chisq.test()} that prints a table including
observed and expected counts, contribution to the chi-squared statistics and residuals.
\\
\texttt{zscore()} & convert a numeric vector into z-scores.
\\
\texttt{D()}, \texttt{antiD()} & derivative and antiderivative operators that take a function
as input and return a function.   For simple functions, the operations are done symbolically.
\\
\texttt{col.mosaic()} & a \CRANpkg{lattice} theme with colors that project better that the 
\CRANpkg{lattice} defaults.
\\
\texttt{dot()}, \texttt{project()}, \texttt{vlength()} & linear algebra on vectors.
\\
\texttt{ediff()} & like \texttt{diff()}, but the returned vector is padded with \texttt{NA}s
so that the length is the same as the input vector.
\\
\texttt{SAD()}, \texttt{MAD} & all pairs sum and mean of absolute differences
\\
\texttt{rgeo} & randomly sample latitidue, longitude pairs uniformly over the globe
\\
\end{tabular}
\caption{Some additional functions in the \CRANpkg{mosaic} package.}
\label{tbl:otherstuff}
\end{table}


# Discussion

## Advantages of the mosaic approach

One of the keys to successfully empowering students to think with data is providing them 
both a conceptual framework that allows them to know what to look for and how to interpret
what they find, and a computational toolbox that allows them to do the looking.
The approach made possible with the \CRANpkg{mosaic} package simplifies 
the transition from thinking to computing by reducing the number of computational templates
students learn so that cognitative effort can be spent elsewhere, and 
having those templates reflect, support, and deepen the underlying thinking \cite{Grolemund:ISR:2014}.
Because of the connection between conceptual understanding and these computational tools,
the use of R can also reveal misunderstandings that might otherwise go unnoticed.

For students who take additional courses after the first course, R has the capability to
support the increasing complexity of the data and analyses students encounter in subsequent
courses and research projects.  Eventually, students will need to learn more about the 
structure of R as a language, the types of objects it supports, and alternative ways of
approaching the same task.  But early on, it is more important that students can successfully
and independently exercise computational and statistical creativity.


## Challenges of using R in introductory courses

But using R is not without some challenges.  The first challenge is to get all of the students
up and running with R.  The use of an RStudio server allows an institution
or instructor to install and configure R and its packages and students to work within a web 
browser, essentially eliminating the start-up costs for the students.  Otherwise, instructors
must assist students as they navigate installation of R and whichever additional packages
are required.  

Once students have access to R, the \CRANpkg{mosaic} package reduces, but does not eliminate,
the amount of syntax students need to learn.  Emphasizing the similarity among commands 
within a template, reminding students that R is case sensitive, taking advantage of short cuts
like tab completion and code history navigation, and explicitly teaching students
how to interpret some of the most common R error messages go a long way toward smoothing
the transition to a command line interface that is not as forgiving as Google search, which 
may be many students' only other experience with a command line interface.

In our experience, the most commonly occuring struggles for students using \CRANpkg{mosaic}
are

 1. General axiety over typing commands.
 
    Although students are very familiar with using computers and computerized devices like smart phones, 
    many of them have little experience typing commands that require following syntax rules.  The 
    "Less Volume, More Creativty" approach helps with this, by reducing the volume, but it remains
    important to highlight repeatedly the similarities among commands and to help students learn to 
    understand the most common error messages R produces so that they can quickly, easily, and comfortably
    recover from innevitibale typing errors.  Even if a class does not typically meet in a computer laboratory
    or invite students to bring laptops to class, it can be useful to arrange some sessions early in 
    the course where students are using RStudio while someone is there to quickly help them when 
    they get stuck.  Avoiding frustration in students' early experience with R goes a long way 
    overcoming anxiety.
    
    As a bonus instructional method, the authors make frequent
    typing mistakes in front of the class.  While we could not avoid this if we tried, it does serve to 
    demonstrate both how to recover from errors and that nothing drastic has happened when an error 
    message is displayed.
    
    One big advantage of the command line interface is that it is much easier to help students by email 
    or in a discussion forum.  Encourage students to copy both their commands and the error messages or 
    output that were produced.  We find students are much more capable of doing this than they are of 
    correctly describing the chain of events they initiated in a menu-driven system.  (It is also much
    easier to give detailed instructions and examples.)
    
 2. Confusion over the tilde (`~`).
 
    It is a small symbol, easily overlooked on the screen or on paper, so students
    will sometimes omit it, or put it where it doesn't belong.  For several of our functions, 
    we allow `x` in place of
    `~ x` to help easy the pain of mistyping things.  But we recommend that
    instructors teach the use of `~` in all situations.  A similar thing occurs
    with `data = `, which is not required for the \CRANpkg{lattice} functions, but
    is for several others.  Teaching the forms that work in all contexts is easier
    than teaching which contexts allow which forms.
 
 3. Difficulty in setting up the R environment
 
    This is all but eliminated when using and RStudio server, but in situations where instructors prefer
    a local R installation for each student, there are often a few issues involved in getting all students
    up and running.  Installation of R and RStudio is straightforward, but one should make sure that students
    all have the latest version of each.  To use the \CRANpkg{mosaic} package, a number of additional packages
    must be installed.  We recommend beginning with 
```{r, eval = FALSE}
update.packages()
```
or the eqivalent operation from the RStudio Packages tab to make sure all packages currently on the system
are up to date.  In most cases,
```{r, eval=FALSE}
install.packages("mosaic")
```
(again, this can also be done via the Packages tab in RStudio) will take care of the rest.  But ocassionally
some package will not install correctly on a particular student's computer. Installing that package
directly rather than as part of the dependencies of \CRANpkg{mosaic} often solves this problem or at 
least provides a useful diagnostic regarding what the problem might be.
 
*Add/delete items here before final submission.* 

## Better bootstrap confidence intervals

The percentile and "t with bootstrap standard error" confidence intervals have been 
improved upon in a number of ways.  We generally do little more than mention this fact
to students in a first course.
One improvement is the bootstrap-t interval.
Rather than attempting to determine the best degrees of freedom for a Student's t-distribution, 
the bootstrap-t approximates the actual distribution of 
$$
t = \frac{\hat{\theta} - \theta}{SE}
$$
using the boostrap distribution of
$$
t^* = \frac{\hat{\theta^*} - \hat{\theta}}{SE^*} \; ,
$$
where $\hat{\theta^*}$ and $SE^*$ are the estimate and estimated standard error
computed from each bootstrap distribution.
Implementing the bootstrap-t interval requires either an extra level of conceptual 
framework or much more calculation to determine the values of $SE^*$.  If a standard error 
formula exists (e.g., $SE = s/\sqrt{n}$), this can be applied to each bootstrap
sample along with the estimator.  An alternative is to iterate the bootstrap procedure
(resampling from each resample) to estimate $SE^*$.  Since standard errors are easier 
to estimate than confidence intervals, fewer resamples are required (per resample)
at the second level; nevertheless, the additional computational overhead is significant.

The \CRANpkg{mosaic} package does not attempt to provide a general framework for the bootstrap-t
or other "second-order accurate" boostrap methods.  Packages such as \CRANpkg{resample}
are more appropriate for situations where speed and accuracy are of utmost importance.
But the bootstrap-t confidence interval can be computed using `confint()`, `do()` and `favstats()`
in the case of estimating a single mean or the difference between two means.

In the example below, we consider the variable `i1` the average number of drinks (standard units)
consumed per day for the 30 days prior to joining the HELP study.  This variable has 
a skewed distribution and so highlights the differences between the methods.

```{r}
densityplot( ~ i1, data = HELPrct)
```

```{r}
BootT1 <- do(1000) * favstats(~ i1, data = resample(HELPrct))
confint(BootT1, method = "boot")
BootT2 <- do(1000) * favstats(i1 ~ sex, data = resample(HELPrct, groups = sex))
confint(BootT2, method = "boot")
```
\noindent
This can also be accomplished manually, although the computations are little bit involved
for the 2-sample case.  Here are the manual computations for the 1-sample case:
```{r, fig.keep = "last"}
estimate <- mean( ~i1, data = HELPrct); estimate
SE <- sd( ~ mean, data = BootT1); SE
T <- with(BootT1, (mean - mean(mean)) / (sd/sqrt(n)))
densityplot(~T)
plotDist("norm", add = TRUE, col="gray50")
q <- quantile(T, c(0.975, 0.025)); q
estimate - q * SE
```

## Efficiency Issues

For applications where speed is of utmost 
importance, it is better to avoid some of the \CRANpkg{mosaic} wrappers. 
For example, for the numerical summary functions, the \CRANpkg{mosaic} versions cannot be
faster than their counterparts in \CRANpkg{base} or \CRANpkg{stats} (because 
eventually they call the underlying functions) and may be noticeable slower in contexts where
they are called many times.
In particular, using the formula interface requires parsing the formula and 
creating a new object to contain the data described by the formula.
```{r}
microbenchmark::microbenchmark( 
  base::mean(rnorm(1000)), 
  mosaic::mean(rnorm(1000)), 
  mosaic::mean(~ rnorm(1000)))
microbenchmark::microbenchmark( 
  base::mean(rnorm(10000)), 
  mosaic::mean(rnorm(10000)), 
  mosaic::mean(~ rnorm(10000)))
```

On the other hand, for aggregated numerical summaries, the loss in performance may represent
a small price to pay for the simplified syntax.
```{r}
microbenchmark::microbenchmark( 
  aggregate = with(iris, aggregate(Sepal.Length, list(Species), base::mean)),
  dplyr = iris %>% 
    sample_frac(size = 1.0, replace = TRUE) %>% 
    group_by(Species) %>% 
    summarise(mean = base::mean(Sepal.Length)),
  mosaic = mean(Sepal.Length ~ Species, data = resample(iris))
)
```

Similarly, using `do()` comes at a price, although here the price has more to do with 
the extra work involved in culling the objects and reformatting the results.  The looping
itself is as fast as using `replicate()` -- indeed the underlying code is very similar.  

```{r}
microbenchmark::microbenchmark( times = 50,
  do = do(500) * diffmean( age ~ shuffle(sex), data = HELPrct),
  replicate = replicate(500, diffmean( age ~ shuffle(sex), data = HELPrct))
)
```
\noindent
Furthermore, `do()` can take advantages of multiple cores if the \CRANpkg{parallel} package 
is attached.  Even on a laptop with a single quad-core processor, the speed-up is noticible.
```{r}
library(parallel)
options("mosaic:parallelMessage" = FALSE)
microbenchmark::microbenchmark( times = 50,
  do = do(500) * diffmean( age ~ shuffle(sex), data = HELPrct),
  replicate = replicate(500, diffmean( age ~ shuffle(sex), data = HELPrct))
)
```

# Acknowledgements

Partial support for this work was provided by the National Science Foundation 
DUE 0920350 (Project MOSAIC).

## More about R Journal submissions

This file is only a basic article template. For full details of _The R Journal_ style and information on how to prepare your article for submission, see the [Instructions for Authors](http://journal.r-project.org/latex/RJauthorguide.pdf).


\bibliography{RJreferences}
