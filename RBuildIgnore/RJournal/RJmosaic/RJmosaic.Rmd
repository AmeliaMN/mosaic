---
title: The mosaic package; helping students to 'think with data' using R
author:
  - name: Randall Pruim
    affiliation: Calvin College
    address:
    - 3201 Burton St SE
    - Grand Rapids, MI 49546
    email:  rpruim@calvin.edu
  - name: Daniel T Kaplan
    affiliation: Macalester College
    address:
    - address 1
    - address 2
    email:  dtkaplan@macalester.edu
  - name: Nicholas J Horton
    affiliation: Amherst College
    address:
    - Department of Mathematics and Statistics
    - PO Box 5000  AC \#2239
    - Amherst, MA 01002-5000
    email:  nhorton@amherst.edu
abstract: >
  Statistics students need to be able to express statistical computations if they are able to make sense of the data around them. The mosaic package provides a simplified and systematic introduction to the core
  functionality related to descriptive statistics, graphical representations, and modeling required in first and second courses in statistics.  This 
  introduction to the package describes some of the guiding principles behind the 
  design of the package, provides illustrative examples of several of the most 
  important functions it implements, and describes ways to help students ``think with data" using R in their early course work.
preamble: >
  % Any extra latex you need in the preamble
output: rticles::rjournal_article
---

```{r, include=FALSE}
require(mosaic)
knitr::opts_chunk$set(
  fig.width = 3, fig.height = 2, 
  fig.show="hold", fig.align = "center",
  cache=TRUE
)
options(digits = 3)
trellis.par.set(theme = col.mosaic())
trellis.par.set(fontsize = list(text=8, points = 5))
set.seed(123)
```

# Motivation

Many have argued that students need additional facility to express statistical computations in order to make sense of the increasingly rich data that is available to them (CITE NOLAN AND TEMPLE LANG 2010; Ridgway 2015 ISR; Horton, Baumer, and Wickham 2015).

To be able to "think with data" (as coined by Diane Lambert of Google), students need to access to commonplace tools for data management, exploratory analysis, visualization, and modeling.  We have demonstrated that it is feasible to integrate computing into our curricula: early and often.


# A guiding principle: Less volume, more creativity

The \CRANpkg{mosaic} package originated in early attempts by each of the authors to 
ease new users into using R, primarily in the context of 
undergraduate statistics courses, and, in one case, also in calculus.
One of the guiding principles behind the development of the \CRANpkg{mosaic} package
has been "Less volume, more creativity".  Beginners are easily overwhelmed by the 
scope of R and its many packages.  Often there are multiple ways to accomplish the 
same task, and authors of the many packages are not required to follow any particular
style guidelines.

Early on in the development of \CRANpkg{mosaic}, we decided to
reduce the number of code templates that users would need to know to as few as possible,
while still providing them with substantial power to be creative within the
templates provided. 

# The formula template

To successfully implement a "less volume, more creativity" approach, one must decide
which tasks are most important to accomplish.  We knew from the outset, that
this would include graphical and numerical summaries of data and various models
and inference procedures.  Because of this, 
our most important template makes use of a "formula interface''
modeled after \code{lm()} and the plotting functions in \CRANpkg{lattice}. 

We typically introduce the formula template in the context of exploring 
two variables as 

```{r, eval=FALSE}
goal( y ~ x, data = mydata )
```
\noindent
For a plot, `goal` will name the type of plot, `y` and `x` name the variables to be 
mapped to the vertical and horizontal axes, and `mydata` is the data frame in which 
these variables are found.
This template allows us to create, for example, scatterplots and side-by-side box plots
```{r}
xyplot(length ~ width, data = KidsFeet)
```
```{r}
bwplot(length ~ sex,   data = KidsFeet)
bwplot(sex ~ length,   data = KidsFeet)
```
\noindent
With the \CRANpkg{mosaic} package attached, we can use the same template to create 
numerical summaries like
```{r}
mean(length ~ sex, data = KidsFeet)
sd(length ~ sex, data = KidsFeet)
```
\noindent
and we have introduced a `tally()` function for counting categorical variables.
```{r}
tally(sex ~ substance, data = HELPrct)
tally(sex ~ substance, data = HELPrct, format = "proportion")
tally(sex ~ substance, data = HELPrct, margins = TRUE)
```

Formula interfaces are provided for 
`mean()`, `median()`, 
`sd()`, `var()`, `cor()`, `cov()`,
`quantile()`, 
`max()`, `min()`, `range()`, 
`IQR()`, `iqr()`, `fivenum()`,
`prod()`, and `sum()`.
In each case we have been careful not to break behavior of the underlying functions from
\CRANpkg{base} and \CRANpkg{stats}, but for applications where speed is of utmost 
importance, it is better to avoid the \CRANpkg{mosaic} wrappers, which cannot be faster (since
the call the underlying functions eventually) and may be noticeable slower in contexts where
they are called many times.
In particular, using the formula interface requires parsing the formula and 
creating a new object to contain the data described by the formula.
```{r}
microbenchmark::microbenchmark( 
  base::mean(rnorm(1000)), 
  mosaic::mean(rnorm(1000)), 
  mosaic::mean(~ rnorm(1000)))
microbenchmark::microbenchmark( 
  base::mean(rnorm(10000)), 
  mosaic::mean(rnorm(10000)), 
  mosaic::mean(~ rnorm(10000)))
```

On the other hand, for aggregated numerical summaries, the loss in performance may represent
a small price to pay for the simplified syntax.
```{r}
microbenchmark::microbenchmark( 
  aggregate = with(iris, aggregate(Sepal.Length, list(Species), base::mean)),
  dplyr = iris %>% 
    sample_frac(size = 1.0, replace = TRUE) %>% 
    group_by(Species) %>% 
    summarise(mean = base::mean(Sepal.Length)),
  mosaic = mean(Sepal.Length ~ Species, data = resample(iris))
)
```

The formula template can be extended to handle one variable or more than two variables,
but we recommend introducing it in the context of two-variable plots and summaries.
This is for several reasons: (1) two-variable plots and numerical summaries are are more
"impressive" and less likely to be something students can as readily do with tools they 
already know, (2) working with more than one variable from the start (correctly) suggests
that the most interesting parts of statistics involve more than one variable, and 
(3) the formula syntax for a single variable makes more sense in the context of two-sided
formulas that it does in isolation.

Once the two-variable summaries are understood, we can add a third and forth variable with
```{r, eval=FALSE}
goal( y ~ x | z, groups = mygroups, data=mydata )
```
\noindent
When plotting, `z` is used to create plots with subpanels (or facets) and `groups` is
used overlay multiple layers.
```{r}
densityplot( ~ age | sex, groups = substance, data = HELPrct)
```

For numerical summaries, these play the same role which allows us to compute 
numerical summaries by changing the name of the plot into the name of the desired
summary.
```{r}
mean( ~ age | sex, groups = substance, data = HELPrct)
```

The one-variable template can be obtained by removing the left-hand side from the formula
in a two-variable template.
```{r, eval=FALSE}
goal( ~ x, data=mydata )
```
\noindent
In the context of plotting, this makes sense since we are providing the data for the 
$x$-axis and allowing R to compute values for the $y$-axis:
```{r}
histogram( ~ age, data = HELPrct)
```
\noindent
Numerical summaries fit this pattern by analogy (and because R formulas are required to
have a right hand side).
```{r}
mean( ~ age, data = HELPrct)
```

As students become familiar with the formula interface,
all three forms can be brought together into a single template:

```{r, eval=FALSE}
goal( formula, data=mydata, ... )
```
\noindent
The formula template allows us to very quickly introduce students to 
thinking about relationships between and among two or more variables and
allows them to test conjectures using graphical and numerical summaries.
Having learned the formula interface to graphical and numerical
summaries early on, new users are well prepared for modeling with
\code{lm()}, \code{glm()}, and various "test" functions such as
`t.test()` when the time comes and they begin early to train their minds
to ask questions of the form "How does this depend on that (and some other things)?". 

By emphasizing the formula template, each of the following commands can be 
viewed as instances of a common template, rather than as separate things 
to learn.

```{r, tidy=FALSE, eval=FALSE}
bwplot(age ~ sex, data=HELPrct)
  mean(age ~ sex, data=HELPrct)
    sd(age ~ sex, data=HELPrct)
    lm(age ~ sex, data=HELPrct)
t.test(age ~ sex, data=HELPrct) 
```

Similarly, by adding additional formula interfaces to `t.test()`,
`binom.test()`, and `prop.test()`, and adding some additional 
plot types, for one-variable situations we have 

```{r, tidy=FALSE, eval=FALSE}
       mean( ~ age, data=HELPrct)
         sd( ~ age, data=HELPrct)
   favstats( ~ age, data=HELPrct)
  histogram( ~ age, data=HELPrct)
    dotPlot( ~ age, data=HELPrct)   # dot plots
freqpolygon( ~ age, data=HELPrct)   # frequency polygon
    ashplot( ~ age, data=HELPrct)   # average shifted histogram
     t.test( ~ age, data=HELPrct)   # formula interface added in mosaic
 binom.test( ~ sex, data=HELPrct)   # formula interface added in mosaic
  prop.test( ~ sex, data=HELPrct)   # formula interface added in mosaic
```

Adding covariates to one or two variable graphically or numerical summaries
fits readily into the template as well.
```{r, tidy=FALSE, eval=FALSE}
     mean( ~ age | sex, data=HELPrct)
       sd( ~ age | sex, data=HELPrct)
histogram( ~ age | sex, data=HELPrct)
   t.test( ~ age | sex, data=HELPrct)
```

While creating the correct formula can produce some initial challenges for users, 
clearly explaining the roles of each component for plotting, 
for numerical summaries, and for model fitting helps demystify the situation. 
We have also found that explicit, early, low-stakes assessment of student mastery
of the formula interface greatly improves student performance.


## Handling missing data

When there are missing values, 
the numerical summary functions in \CRANpkg{base} and \CRANpkg{stats} return
results that surprise and confuse new users.
```{r}
mean( ~ dayslink, data = HELPmiss)
mean( ~ dayslink, data = HELPmiss, na.rm = TRUE)
```
We offer two solutions to this situation.  Our favorite is the `favstats()` function
which computes a number of our favorite numerical summaries on the non-missing values
but also reports the number of missing values.
```{r}
favstats( ~ dayslink, data = HELPmiss)
```

Users also have the option of changing the default for `na.rm` if they like.
This will, of course, only affect the \CRANpkg{mosaic} versions of these functions.

```{r}
options(na.rm = TRUE)
mean(~ dayslink, data = HELPmiss)
base::mean(HELPmiss[["dayslink"]], data = HELPmiss)
```

##  Creating and using functions

Especially in calculus, but also in statistics, it is useful to create 
functions defined by algebraic formulas.  With `makeFun()` we can construct
such functions using a formula interface, and use `plotFun()` to plot them.

```{r}
f <- makeFun(A + B * log(x) ~ x, A = 1, B = 1)
f
f(2)
plotFun(f(x) ~ x, xlim = c(0,3))
```

More interestingly for statistics, we can use `makeFun()` to create functions from
model objects created by `lm()` and `glm()`.
```{r, fig.keep = "last"}
cars.mod <- lm(dist ~ poly(speed,2), data = cars)
dist <- makeFun(cars.mod)
dist(speed = 15)
dist(speed = 15, interval = "confidence")
xyplot(dist ~ speed, data = cars)
plotFun(dist(s) ~ s, add = TRUE)
```

\noindent
For logistic regression with factors, we need to adjust things slightly when plotting
because the model functions returns values between 0 and 1, but 2-level factors are coded 
as 1 and 2.
```{r}
Feet.mod <- glm(sex ~ width, data = KidsFeet, family = binomial)
s <- makeFun(Feet.mod)
s(width = 8.5)
xyplot(sex ~ width, data = KidsFeet)
plotFun(1 + s(w) ~ w, add = TRUE)
```

This wrapper around `predict()` is easier for beginners to use because 
(a) it returns a function to which inputs can be supplied without creating a data frame, 
(b) the resulting function returns values on the response scale by default, and (c) it 
back transforms a few common transformations of the response variable, 
including `log()` and `sqrt()` (and allows the user to provide a custom value to
the `transform` argument to handle other cases).
```{r, message = FALSE, fig.keep = "last"}
mtcars.mod <- lm(log(mpg) ~ log(wt) + factor(cyl), data = mtcars)
mileage <- makeFun(mtcars.mod)
xyplot(mpg ~ wt, data = mtcars, groups = cyl)
plotFun( mileage(w, cyl=4) ~ w, add = TRUE, col = 1)
plotFun( mileage(w, cyl=6) ~ w, add = TRUE, col = 2)
plotFun( mileage(w, cyl=8) ~ w, add = TRUE, col = 3)
```

For many simple models, creating a plot can be even simpler
```{r}
plotModel(cars.mod)
mtcars.mod2 <- lm(mpg ~ log(wt) + factor(cyl) + factor(am), data = mtcars)
plotModel(mtcars.mod2)
```

# Randomization and Resampling

The \CRANpkg{mosaic} package also provides functionality to support teaching inference
based on randomization tests and bootstrap methods.  Our goals was to focus attention
on the important parts of these techniques (e.g., where randomness enters in and how to
use the resulting distribution) while hiding some of the technical details
involved in creating loops and accumulating values.

As a first example, we often introduce the story of the lady tasting tea.  (See
\cite{LadyTastingTea} for the details of this famous story.)  But here we will
test a coin to see whether it is a "fair coin".  Suppose we flip the coin 20 times
and observe only 6 heads, how suspicious should we be that the coin is not fair?
The statistical punchline for either the lady tasting tea or testing a coin 
is that we want to compute the p-value for a binomial 
test via simulations rather than using formulas for the binomial distribution or 
normal approximations. This allows us to introduce this example on the first day of class.

Since students do not know about distributions yet, but do understand the idea of a coin
toss, we have provided `rflip()` to simulate tossing a coin one or several times:
```{r}
rflip()
rflip(20)
```
To test a null hypothesis of a fair coin, we need to simulate flipping 20 coins many times,
recording for each simulation the number of heads that were observed.
The `do()` function allows us to do just that using the following template

```{r eval = FALSE}
do(n) * {stuff to do}
```
\noindent
where stuff to do is typically a single R command, but may be something more complicated.
For example, we can flip 100 coins three times as follows.
```{r}
do(3) * rflip(100)
```
\noindent
Notice that `do()` (technically `cull_for_do()`) has been clever about what information 
is stored for each group of 100 coin tosses.  It is now a simple matter to do this many more
times and use numerical or graphical summaries to investigate how unusual it is to get
so few heads if the coin is indeed a fair coin.
```{r}
Sims <- do (1000) * rflip(20)
histogram( ~ heads, data = Sims, width = 1, groups = heads <= 6)
tally ( ~(heads <= 6), data = Sims)
```
\noindent
(If you are familiar with \CRANpkg{lattice}, you will notice that the \CRANpkg{mosaic} package
also adds some additional arguments to the `histogram()` function.)

## sample(), resample(), and shuffle()

To facilitate randomization and bootstrapping, \CRANpkg{mosaic} extends `sample()` to operate
on data frames, `shuffle()` as an alternative name for `sample()`, and `resample()` which
is `sample()` with `replace = TRUE`.  With these in hand, all of the tests and confidence
intervals seen in traditional first course in statistics can be performed using a common
outline:

  1. Do it to your data
  2. Do it to a randomized version of your data
  3. Do it to lots of randomized versions of your data.
  
For example, we can use randomization in place of the two-sample t test to
obtain an empirical p-value.
```{r}
pval(t.test(age ~ sex, data = HELPrct, alternative = "greater"))
```

```{r}
D <- diffmean(age ~ sex, data = HELPrct); D
do(1) * diffmean(age ~ shuffle(sex), data = HELPrct)
Null.dist <- do(5000) * diffmean(age ~ shuffle(sex), data = HELPrct)
histogram(~diffmean, data = Null.dist, v = D)
prop( ~(diffmean < D), data = Null.dist, format = "prop")
```
The example above introduces three additional \CRANpkg{mosaic} functions.
`pval()` extracts the p-value from an object of class `"htest"`; 
`prop()` computes the proportion of logical vector that is (by default) `TRUE` 
or of a factor that is (by default) the first label;
and
`diffmean()` is similar to `diff(mean()`, but labels the result differently.
`diffprop()` works similarly for differences in proportions.

If we are interested in a confidence interval for the mean difference, we can use
`resample()` and `do()` to generate a bootstrap distribution in one of two ways.
```{r}
Boot.dist1 <- do(1000) * diffmean(age ~ sex, data = resample(HELPrct))
Boot.dist2 <- do(1000) * diffmean(age ~ sex, data = resample(HELPrct, groups = sex))
```
\noindent
In the second example, the resampling happens within the sex groups so that the marginal
counts for each sex remain fixed.

```{r, include=FALSE}
set.seed(123456)
```
```{r}
favstats(age ~ sex, data = HELPrct)
favstats(age ~ sex, data = resample(HELPrct))
favstats(age ~ sex, data = resample(HELPrct, groups = sex))
```

Using either bootstrap distribution, we can compute a simple percentile interval
by finding the range of a central portion of the bootstrap distribution.
Visually inspecting the bootstrap distribution for skew and bias is an important
step to make sure the percentile interval is not being applied in a situation where 
it may perform poorly.
```{r}
histogram( ~ diffmean, data = Boot.dist2, v = D)
qqmath( ~ diffmean, data = Boot.dist2)
cdata( ~ diffmean, p = 0.95, data = Boot.dist2)
```

Alternatively, we could compute a confidence interval based on a bootstrap 
estimate of the standard error.
```{r}
SE <- sd( ~ diffmean, data = Boot.dist2); SE
D + c(-1,1) * 2 * SE
```
\noindent
(How to replace 2 with an appropriate value to create more accurate intervals
or to allow for different confidence levels is a matter of some subtlety.
See \cite{Hesterberg:2015}.)

Each of these can be further automated using an extension to `confint()`.
```{r}
confint(Boot.dist2, method = c("percentile", "stderr"))
```


# Extracting information

Modeled on functions like \code{resid()}, a number of additional functions have
been added to \CRANpkg{mosaic} to facilitate extracting information from more
complicated objects.  Some examples include

```{r, extractors}
confint(t.test(~age, data=HELPrct))     # works for any "htest" object
pval(t.test(age ~ sex, data=HELPrct))   # works for any "htest" object
stat(t.test(age ~ sex, data=HELPrct))   # works for any "htest" object
r.squared(lm(age ~ sex, data=HELPrct))
```


# Some additional bells and whistles

## Visualizing distributions of random variables

A number of functions make it simple to visualize random variables.  `plotDist()` creates
displays for any distribution for which the standard d/p/q functions exist.
```{r}
plotDist("norm", mean = 100, sd = 10)
plotDist("binom", size = 100, prob = 0.3)
```
\noindent
Tail probabilities can be highlighted using the `groups` argument.
```{r}
plotDist("chisq", df = 4, groups = x > 9)
plotDist("chisq", df = 4, groups = x > 9, type = "h")
```
\noindent
Using the `kind` argument, we can obtain other types of plots, including cdfs and 
probability histograms.
```{r}
plotDist("norm", mean = 100, sd = 10, kind = "cdf")
plotDist("binom", size = 100, prob = 0.3, kind = "histogram")
```

For several distributions, we provide augmented versions of the distribution and 
quantile functions that assist students in understanding what values are returned
by functions like `pnorm()` and `qnorm()`.
```{r}
xpnorm(-2:2)
xqt(0.975, df = 20)
```

## What other things do we want to show?

Some candidates:

  * `bargraph()`
  * `CIsim()`
  * `mplot()`
  * `panel.lmbands()`
  * `plotPoints()`
  * `statTally()`
  * `TukeyHSD()`
  * `xchisq.test()`
  * `zscore()`

# Calculus in R

Need to decide what if anything to include about calculus.

# Acknowledgements

Partial support for this work was provided by the National Science Foundation DUE 0920350 (Project MOSAIC).



## More about R Journal submissions

This file is only a basic article template. For full details of _The R Journal_ style and information on how to prepare your article for submission, see the [Instructions for Authors](http://journal.r-project.org/latex/RJauthorguide.pdf).



\bibliography{RJreferences}
%\bibliography{pruim-horton-kaplan}
